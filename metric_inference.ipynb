{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "!pwd"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/opt/ml/image-classification-level1-04\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from pytorch_metric_learning.utils.inference import MatchFinder, InferenceModel\n",
    "from pytorch_metric_learning.distances import CosineSimilarity\n",
    "from pytorch_metric_learning.utils import common_functions as c_f\n",
    "from model.model import PretrainModelTimmArc\n",
    "from data_loader.datasets import MaskDataset, MaskSubDataset, MaskSubmitDataset\n",
    "from data_loader.data_loaders import MaskDataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create the datset and load the trained model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\n",
    "data_loader_args = {\n",
    "    \"data_dir\": \"../input/data\",\n",
    "    \"batch_size\": 32,\n",
    "    \"shuffle\": False,\n",
    "    \"validation_split\": 0.1,\n",
    "    \"num_workers\": 2,\n",
    "    \"submit\": True,\n",
    "    \"sampler\": \"no\"\n",
    "}\n",
    "train_data_loader, valid_data_loader, submit_data_loader = MaskDataLoader(**data_loader_args).split_validation()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current transforms : None\n",
      "num_workers:  2\n",
      "No sampling method\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:688: FutureWarning: This class has been deprecated. Please use CoarseDropout\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train_dataset = train_data_loader.dataset\n",
    "valid_dataset = valid_data_loader.dataset\n",
    "submit_dataset = submit_data_loader.dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "model = PretrainModelTimmArc()\n",
    "checkpoint = torch.load(\"/opt/ml/image-classification-level1-04/model_best.pth\")\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# model = torch.nn.DataParallel(model)\n",
    "print(\"done model loading\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "done model loading\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate Validation set based on Train set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from pytorch_metric_learning import losses, miners, distances, reducers, testers\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model.to(device)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PretrainModelTimmArc(\n",
       "  (model): EfficientNet(\n",
       "    (conv_stem): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): SiLU(inplace=True)\n",
       "    (blocks): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): DepthwiseSeparableConv(\n",
       "          (conv_dw): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "          (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pw): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Identity()\n",
       "        )\n",
       "        (1): DepthwiseSeparableConv(\n",
       "          (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n",
       "          (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "          (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "          (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
       "          (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "          (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "          (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "          (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "          (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)\n",
       "          (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "          (bn2): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "          (bn2): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "          (bn2): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "          (bn2): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (5): InvertedResidual(\n",
       "          (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "          (bn2): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)\n",
       "          (bn2): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
       "          (bn2): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_head): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act2): SiLU(inplace=True)\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (classifier): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "  )\n",
       "  (metric_fc): ArcMarginProduct()\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def get_all_embeddings(dataset, model):\n",
    "    tester = testers.BaseTester(normalize_embeddings=True,\n",
    "                    use_trunk_output=False,\n",
    "                    batch_size=64,\n",
    "                    dataloader_num_workers=4,\n",
    "                    pca=None,\n",
    "                    data_device=device,\n",
    "                    dtype=None,\n",
    "                    data_and_label_getter=None,\n",
    "                    label_hierarchy_level=0,\n",
    "                    end_of_testing_hook=None,\n",
    "                    dataset_labels=None,\n",
    "                    set_min_label_to_zero=False,\n",
    "                    accuracy_calculator=None,\n",
    "                    visualizer=None,\n",
    "                    visualizer_hook=None,)\n",
    "    return tester.get_all_embeddings(dataset, model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def test(train_set, test_set, model, accuracy_calculator):\n",
    "    train_embeddings, train_labels = get_all_embeddings(train_set, model)\n",
    "    print(train_labels)\n",
    "    test_embeddings, test_labels = get_all_embeddings(test_set, model)\n",
    "    train_labels = train_labels.squeeze(1)\n",
    "    test_labels = test_labels.squeeze(1)\n",
    "    print(\"Computing accuracy\")\n",
    "    accuracies = accuracy_calculator.get_accuracy(test_embeddings, \n",
    "                                                train_embeddings,\n",
    "                                                test_labels,\n",
    "                                                train_labels,\n",
    "                                                False)\n",
    "    print(\"Test set accuracy (Precision@1) = {}\".format(accuracies[\"precision_at_1\"]))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "accuracy_calculator = AccuracyCalculator(include = (\"precision_at_1\",), k = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "test(train_dataset, valid_dataset, model, accuracy_calculator)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 266/266 [00:33<00:00,  8.04it/s]\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 1],\n",
      "        [10],\n",
      "        [ 4],\n",
      "        ...,\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [ 0]], device='cuda:0')\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 30/30 [00:04<00:00,  6.49it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Computing accuracy\n",
      "Test set accuracy (Precision@1) = 0.9915344051551074\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inference on the Submit Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "submit_dataset = submit_data_loader.dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create helper functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def print_decision(is_match):\n",
    "    if is_match:\n",
    "        print(\"Same class\")\n",
    "    else:\n",
    "        print(\"Different class\")\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "inv_normalize = transforms.Normalize(\n",
    "   mean= [-m/s for m, s in zip(mean, std)],\n",
    "   std= [1/s for s in std]\n",
    ")\n",
    "\n",
    "def imshow(img, figsize=(8, 4)):\n",
    "    img = inv_normalize(img)\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize = figsize)\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "labels_to_indices = c_f.get_labels_to_indices(train_dataset.get_labels().values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "labels_to_indices"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {1: array([    0,    15,    24, ..., 16979, 16994, 16999]),\n",
       "             10: array([    1,     8,    30,    40,    92,   138,   146,   190,   197,\n",
       "                      206,   211,   281,   286,   288,   291,   298,   330,   333,\n",
       "                      334,   374,   450,   459,   473,   479,   497,   539,   551,\n",
       "                      559,   614,   657,   704,   717,   732,   756,   759,   789,\n",
       "                      796,   807,   849,   850,   854,   864,   867,   908,   929,\n",
       "                      961,   977,  1036,  1074,  1076,  1107,  1115,  1136,  1146,\n",
       "                     1158,  1228,  1231,  1274,  1294,  1309,  1322,  1336,  1491,\n",
       "                     1499,  1506,  1562,  1572,  1581,  1600,  1609,  1616,  1635,\n",
       "                     1683,  1722,  1777,  1783,  1883,  1943,  1970,  1994,  2005,\n",
       "                     2020,  2049,  2064,  2066,  2100,  2114,  2120,  2128,  2161,\n",
       "                     2174,  2205,  2213,  2221,  2227,  2299,  2316,  2349,  2388,\n",
       "                     2419,  2485,  2520,  2554,  2600,  2610,  2614,  2653,  2679,\n",
       "                     2719,  2723,  2752,  2761,  2775,  2779,  2834,  2835,  2851,\n",
       "                     2888,  2907,  2911,  2927,  2929,  2930,  2938,  2945,  3034,\n",
       "                     3081,  3167,  3206,  3231,  3246,  3248,  3252,  3301,  3316,\n",
       "                     3322,  3344,  3356,  3423,  3425,  3437,  3453,  3489,  3513,\n",
       "                     3525,  3537,  3550,  3568,  3570,  3630,  3640,  3649,  3660,\n",
       "                     3665,  3671,  3675,  3701,  3716,  3722,  3726,  3772,  3787,\n",
       "                     3807,  3808,  3816,  3821,  3841,  3854,  3860,  3883,  3884,\n",
       "                     3903,  3978,  4013,  4074,  4075,  4092,  4118,  4127,  4128,\n",
       "                     4132,  4238,  4250,  4253,  4254,  4309,  4324,  4337,  4385,\n",
       "                     4386,  4396,  4547,  4560,  4562,  4595,  4597,  4599,  4642,\n",
       "                     4675,  4681,  4748,  4773,  4786,  4804,  4805,  4807,  4812,\n",
       "                     4833,  4844,  4863,  4906,  4926,  4961,  4984,  5018,  5042,\n",
       "                     5046,  5091,  5125,  5157,  5197,  5202,  5203,  5221,  5234,\n",
       "                     5250,  5287,  5298,  5303,  5318,  5319,  5363,  5409,  5422,\n",
       "                     5429,  5484,  5498,  5540,  5592,  5598,  5608,  5616,  5660,\n",
       "                     5676,  5717,  5726,  5740,  5742,  5746,  5769,  5773,  5800,\n",
       "                     5804,  5877,  5926,  5940,  5952,  5955,  5965,  6011,  6041,\n",
       "                     6087,  6126,  6149,  6161,  6167,  6183,  6189,  6221,  6229,\n",
       "                     6246,  6248,  6275,  6285,  6286,  6290,  6294,  6296,  6314,\n",
       "                     6357,  6381,  6391,  6407,  6428,  6440,  6442,  6458,  6503,\n",
       "                     6525,  6544,  6563,  6608,  6690,  6707,  6718,  6729,  6771,\n",
       "                     6806,  6820,  6858,  6865,  6876,  6885,  6974,  6999,  7050,\n",
       "                     7052,  7106,  7165,  7171,  7229,  7317,  7328,  7357,  7409,\n",
       "                     7414,  7425,  7433,  7439,  7445,  7455,  7457,  7493,  7507,\n",
       "                     7540,  7575,  7587,  7588,  7598,  7607,  7661,  7668,  7697,\n",
       "                     7722,  7755,  7815,  7817,  7828,  7832,  7883,  7887,  7897,\n",
       "                     7902,  7924,  7938,  7950,  7951,  8024,  8046,  8051,  8082,\n",
       "                     8097,  8173,  8176,  8179,  8207,  8229,  8238,  8275,  8279,\n",
       "                     8280,  8312,  8347,  8365,  8368,  8379,  8409,  8427,  8440,\n",
       "                     8442,  8474,  8479,  8484,  8523,  8629,  8660,  8667,  8668,\n",
       "                     8686,  8704,  8714,  8723,  8773,  8827,  8878,  8921,  8941,\n",
       "                     8945,  8948,  8987,  8988,  8994,  9051,  9076,  9114,  9117,\n",
       "                     9142,  9155,  9166,  9167,  9203,  9206,  9215,  9231,  9242,\n",
       "                     9291,  9301,  9306,  9331,  9341,  9342,  9366,  9395,  9405,\n",
       "                     9424,  9526,  9557,  9563,  9664,  9678,  9721,  9732,  9758,\n",
       "                     9808,  9819,  9821,  9830,  9835,  9865,  9873,  9874,  9900,\n",
       "                     9951,  9953,  9986, 10002, 10009, 10069, 10076, 10087, 10113,\n",
       "                    10125, 10199, 10205, 10207, 10211, 10216, 10222, 10238, 10247,\n",
       "                    10274, 10279, 10309, 10322, 10339, 10346, 10408, 10411, 10425,\n",
       "                    10431, 10497, 10533, 10537, 10571, 10583, 10628, 10645, 10648,\n",
       "                    10675, 10721, 10734, 10799, 10804, 10854, 10860, 10884, 10894,\n",
       "                    10923, 10929, 10993, 11032, 11039, 11055, 11065, 11080, 11089,\n",
       "                    11090, 11096, 11103, 11104, 11107, 11118, 11148, 11177, 11183,\n",
       "                    11240, 11252, 11271, 11275, 11285, 11286, 11332, 11333, 11438,\n",
       "                    11440, 11488, 11551, 11565, 11600, 11635, 11683, 11704, 11709,\n",
       "                    11718, 11741, 11846, 11847, 11861, 11870, 11875, 11891, 11904,\n",
       "                    11911, 11934, 11981, 12001, 12016, 12021, 12026, 12116, 12117,\n",
       "                    12138, 12152, 12156, 12284, 12286, 12307, 12309, 12330, 12340,\n",
       "                    12349, 12361, 12477, 12481, 12528, 12558, 12574, 12660, 12663,\n",
       "                    12713, 12737, 12742, 12798, 12802, 12930, 12944, 12950, 12967,\n",
       "                    13005, 13017, 13019, 13028, 13070, 13077, 13125, 13127, 13160,\n",
       "                    13178, 13211, 13235, 13248, 13262, 13353, 13369, 13418, 13423,\n",
       "                    13447, 13462, 13490, 13515, 13533, 13541, 13569, 13581, 13585,\n",
       "                    13591, 13600, 13622, 13630, 13665, 13667, 13668, 13720, 13722,\n",
       "                    13756, 13757, 13758, 13768, 13789, 13813, 13849, 13860, 13875,\n",
       "                    13883, 13886, 13889, 13911, 13958, 13992, 14002, 14005, 14017,\n",
       "                    14026, 14039, 14044, 14059, 14088, 14185, 14195, 14198, 14201,\n",
       "                    14204, 14205, 14234, 14269, 14283, 14284, 14334, 14337, 14341,\n",
       "                    14345, 14406, 14423, 14468, 14475, 14518, 14550, 14558, 14565,\n",
       "                    14591, 14635, 14659, 14673, 14719, 14724, 14805, 14806, 14819,\n",
       "                    14831, 14853, 14879, 14906, 14940, 14955, 14985, 14989, 14991,\n",
       "                    15004, 15048, 15084, 15104, 15115, 15129, 15135, 15152, 15219,\n",
       "                    15226, 15231, 15247, 15248, 15279, 15310, 15315, 15321, 15339,\n",
       "                    15368, 15399, 15489, 15494, 15501, 15530, 15543, 15546, 15551,\n",
       "                    15566, 15645, 15652, 15702, 15703, 15728, 15745, 15763, 15781,\n",
       "                    15797, 15825, 15827, 15847, 15848, 15927, 15969, 16015, 16019,\n",
       "                    16022, 16082, 16154, 16161, 16182, 16194, 16204, 16223, 16252,\n",
       "                    16255, 16279, 16297, 16316, 16349, 16402, 16423, 16432, 16434,\n",
       "                    16441, 16473, 16559, 16580, 16597, 16644, 16690, 16703, 16711,\n",
       "                    16716, 16729, 16779, 16844, 16921, 16931, 16977]),\n",
       "             4: array([    2,    10,    13, ..., 17005, 17007, 17008]),\n",
       "             3: array([    3,    11,    17, ..., 16984, 16985, 17000]),\n",
       "             0: array([    4,    12,    14, ..., 17004, 17006, 17009]),\n",
       "             6: array([    5,    47,    70,    72,   102,   123,   141,   155,   164,\n",
       "                      201,   259,   262,   319,   339,   412,   416,   424,   518,\n",
       "                      555,   645,   730,   763,   858,   930,   978,   983,  1007,\n",
       "                     1017,  1048,  1051,  1077,  1112,  1169,  1225,  1246,  1247,\n",
       "                     1271,  1277,  1281,  1325,  1330,  1390,  1412,  1433,  1442,\n",
       "                     1521,  1631,  1673,  1687,  1704,  1748,  1753,  1771,  1775,\n",
       "                     1785,  1832,  1837,  1839,  1857,  1858,  1887,  1932,  2007,\n",
       "                     2040,  2045,  2094,  2170,  2195,  2289,  2304,  2309,  2345,\n",
       "                     2366,  2384,  2424,  2474,  2476,  2715,  2727,  2743,  2750,\n",
       "                     2782,  2820,  2826,  2839,  2848,  2861,  2870,  2892,  3063,\n",
       "                     3086,  3087,  3090,  3097,  3141,  3182,  3263,  3396,  3408,\n",
       "                     3418,  3461,  3566,  3585,  3650,  3669,  3719,  3795,  3827,\n",
       "                     3836,  3855,  3865,  3871,  3887,  3890,  3952,  3996,  4021,\n",
       "                     4039,  4051,  4071,  4107,  4126,  4378,  4392,  4417,  4456,\n",
       "                     4537,  4544,  4603,  4617,  4732,  4737,  4829,  4852,  4865,\n",
       "                     4952,  4967,  5032,  5052,  5078,  5089,  5137,  5301,  5316,\n",
       "                     5330,  5336,  5345,  5348,  5349,  5412,  5435,  5449,  5461,\n",
       "                     5476,  5486,  5501,  5519,  5558,  5584,  5593,  5621,  5663,\n",
       "                     5687,  5748,  5758,  5799,  5834,  5864,  5876,  5886,  5889,\n",
       "                     5935,  5942,  5947,  5953,  5973,  5974,  5993,  6018,  6047,\n",
       "                     6050,  6125,  6169,  6172,  6211,  6245,  6343,  6415,  6434,\n",
       "                     6435,  6488,  6495,  6537,  6545,  6628,  6659,  6681,  6697,\n",
       "                     6735,  6746,  6833,  6838,  6846,  6933,  6975,  7022,  7094,\n",
       "                     7121,  7155,  7180,  7199,  7202,  7206,  7261,  7278,  7280,\n",
       "                     7327,  7329,  7362,  7371,  7383,  7490,  7525,  7526,  7527,\n",
       "                     7560,  7581,  7584,  7604,  7625,  7629,  7754,  7770,  7785,\n",
       "                     7893,  7990,  7998,  8005,  8106,  8109,  8114,  8182,  8208,\n",
       "                     8341,  8354,  8389,  8406,  8462,  8471,  8477,  8495,  8498,\n",
       "                     8513,  8530,  8545,  8564,  8574,  8610,  8746,  8774,  8779,\n",
       "                     8784,  8793,  8832,  8850,  9017,  9033,  9052,  9133,  9149,\n",
       "                     9172,  9277,  9311,  9376,  9450,  9528,  9564,  9574,  9579,\n",
       "                     9593,  9607,  9618,  9624,  9698,  9740,  9748,  9763,  9795,\n",
       "                     9866,  9882,  9916,  9943, 10016, 10019, 10021, 10036, 10049,\n",
       "                    10050, 10055, 10107, 10150, 10153, 10188, 10246, 10286, 10299,\n",
       "                    10409, 10426, 10436, 10492, 10508, 10512, 10519, 10522, 10551,\n",
       "                    10604, 10649, 10670, 10757, 10815, 10839, 10840, 10843, 10896,\n",
       "                    10906, 10909, 10944, 11004, 11018, 11052, 11056, 11108, 11149,\n",
       "                    11174, 11186, 11201, 11213, 11251, 11253, 11308, 11358, 11439,\n",
       "                    11530, 11640, 11653, 11767, 11783, 11810, 11829, 11849, 11865,\n",
       "                    11954, 11979, 11983, 12024, 12025, 12064, 12072, 12096, 12128,\n",
       "                    12134, 12167, 12190, 12197, 12225, 12262, 12276, 12298, 12398,\n",
       "                    12424, 12514, 12530, 12548, 12557, 12704, 12734, 12773, 12793,\n",
       "                    12796, 12834, 12872, 12874, 12877, 12894, 12895, 12914, 12949,\n",
       "                    12963, 13001, 13023, 13031, 13043, 13061, 13132, 13174, 13276,\n",
       "                    13377, 13383, 13394, 13413, 13469, 13562, 13704, 13727, 13769,\n",
       "                    13781, 13790, 13799, 13866, 13868, 13932, 13946, 13978, 13993,\n",
       "                    14003, 14014, 14055, 14096, 14110, 14184, 14212, 14228, 14248,\n",
       "                    14250, 14253, 14320, 14401, 14422, 14433, 14449, 14508, 14510,\n",
       "                    14585, 14656, 14709, 14725, 14738, 14755, 14773, 14781, 14847,\n",
       "                    14850, 14888, 14890, 14905, 14947, 14976, 14996, 15035, 15047,\n",
       "                    15051, 15064, 15089, 15239, 15275, 15333, 15360, 15371, 15392,\n",
       "                    15462, 15473, 15487, 15592, 15616, 15625, 15708, 15783, 15844,\n",
       "                    15923, 15929, 15983, 16032, 16060, 16150, 16206, 16229, 16260,\n",
       "                    16263, 16307, 16320, 16345, 16351, 16372, 16379, 16390, 16421,\n",
       "                    16537, 16600, 16649, 16668, 16688, 16691, 16747, 16846, 16878,\n",
       "                    16882, 16925, 16998, 17003]),\n",
       "             12: array([    6,    31,    52,    64,   100,   112,   175,   177,   205,\n",
       "                      245,   311,   335,   361,   370,   373,   383,   404,   460,\n",
       "                      498,   538,   607,   678,   696,   721,   786,   799,   837,\n",
       "                      866,   869,   888,   973,   998,  1010,  1015,  1041,  1073,\n",
       "                     1106,  1151,  1205,  1270,  1347,  1441,  1455,  1471,  1488,\n",
       "                     1522,  1551,  1582,  1595,  1601,  1615,  1640,  1737,  1822,\n",
       "                     1843,  1850,  1961,  2018,  2057,  2090,  2117,  2165,  2239,\n",
       "                     2271,  2326,  2338,  2363,  2398,  2483,  2487,  2518,  2558,\n",
       "                     2599,  2620,  2644,  2667,  2697,  2718,  2722,  2878,  2967,\n",
       "                     2977,  3000,  3036,  3079,  3114,  3156,  3175,  3222,  3247,\n",
       "                     3283,  3290,  3353,  3385,  3436,  3473,  3520,  3531,  3667,\n",
       "                     3680,  3709,  3712,  3715,  3745,  3817,  3839,  3882,  3932,\n",
       "                     3945,  3946,  3987,  3988,  4018,  4108,  4109,  4140,  4150,\n",
       "                     4170,  4198,  4212,  4239,  4261,  4274,  4288,  4293,  4342,\n",
       "                     4393,  4460,  4501,  4514,  4541,  4573,  4575,  4578,  4618,\n",
       "                     4653,  4657,  4686,  4704,  4774,  4789,  4826,  4842,  4851,\n",
       "                     4857,  4871,  4927,  4935,  5002,  5044,  5094,  5164,  5180,\n",
       "                     5195,  5260,  5279,  5288,  5294,  5382,  5386,  5410,  5460,\n",
       "                     5505,  5511,  5513,  5576,  5604,  5690,  5729,  5747,  5768,\n",
       "                     5810,  5816,  5822,  5859,  5909,  5945,  6036,  6040,  6093,\n",
       "                     6188,  6239,  6306,  6307,  6322,  6352,  6368,  6398,  6466,\n",
       "                     6512,  6569,  6636,  6738,  6749,  6763,  6787,  6912,  6926,\n",
       "                     7010,  7024,  7107,  7139,  7190,  7219,  7233,  7275,  7334,\n",
       "                     7349,  7370,  7379,  7429,  7509,  7551,  7570,  7591,  7631,\n",
       "                     7632,  7634,  7658,  7672,  7702,  7732,  7738,  7753,  7768,\n",
       "                     7791,  7814,  7888,  7900,  8045,  8047,  8067,  8111,  8146,\n",
       "                     8166,  8167,  8199,  8232,  8244,  8393,  8396,  8400,  8456,\n",
       "                     8473,  8532,  8535,  8568,  8602,  8674,  8691,  8694,  8697,\n",
       "                     8729,  8831,  8862,  8898,  8965,  8983,  9099,  9125,  9139,\n",
       "                     9160,  9258,  9320,  9433,  9441,  9457,  9470,  9502,  9514,\n",
       "                     9523,  9546,  9597,  9632,  9646,  9728,  9750,  9770,  9840,\n",
       "                     9876,  9933,  9954,  9973,  9976, 10020, 10042, 10045, 10056,\n",
       "                    10060, 10162, 10172, 10175, 10223, 10227, 10287, 10292, 10328,\n",
       "                    10334, 10354, 10429, 10467, 10470, 10511, 10547, 10681, 10731,\n",
       "                    10753, 10787, 10788, 10809, 10820, 10922, 10931, 10973, 10983,\n",
       "                    11046, 11066, 11223, 11293, 11324, 11334, 11343, 11357, 11386,\n",
       "                    11402, 11413, 11442, 11465, 11509, 11525, 11549, 11590, 11597,\n",
       "                    11616, 11682, 11693, 11695, 11777, 11813, 11860, 11871, 11880,\n",
       "                    11893, 11899, 11909, 11976, 11987, 12041, 12061, 12088, 12098,\n",
       "                    12195, 12200, 12211, 12230, 12247, 12320, 12366, 12407, 12411,\n",
       "                    12412, 12431, 12441, 12467, 12487, 12490, 12532, 12543, 12747,\n",
       "                    12754, 12759, 12776, 12807, 12809, 12840, 12984, 13015, 13025,\n",
       "                    13038, 13079, 13123, 13128, 13133, 13142, 13159, 13214, 13266,\n",
       "                    13287, 13363, 13410, 13439, 13500, 13566, 13594, 13608, 13641,\n",
       "                    13688, 13733, 13745, 13765, 13787, 13824, 13869, 13991, 13999,\n",
       "                    14132, 14134, 14146, 14182, 14220, 14297, 14311, 14352, 14399,\n",
       "                    14416, 14474, 14499, 14581, 14598, 14617, 14642, 14716, 14867,\n",
       "                    14873, 14896, 14931, 14936, 14939, 14992, 15038, 15145, 15149,\n",
       "                    15153, 15154, 15158, 15192, 15284, 15304, 15345, 15390, 15442,\n",
       "                    15455, 15466, 15490, 15547, 15579, 15586, 15602, 15605, 15650,\n",
       "                    15725, 15736, 15789, 15810, 15821, 15831, 15892, 15900, 15906,\n",
       "                    15914, 15931, 15982, 15989, 16035, 16036, 16087, 16135, 16170,\n",
       "                    16178, 16226, 16256, 16262, 16271, 16319, 16334, 16340, 16403,\n",
       "                    16454, 16484, 16531, 16536, 16568, 16577, 16579, 16601, 16610,\n",
       "                    16633, 16670, 16676, 16677, 16678, 16693, 16698, 16781, 16793,\n",
       "                    16798, 16887, 16906, 17001]),\n",
       "             16: array([    7,     9,    32,    49,    66,    77,    90,   160,   178,\n",
       "                      225,   238,   271,   297,   350,   358,   369,   375,   434,\n",
       "                      443,   456,   480,   481,   491,   640,   659,   672,   673,\n",
       "                      709,   752,   761,   766,   798,   820,   830,   852,   873,\n",
       "                      877,   890,  1046,  1088,  1101,  1147,  1180,  1194,  1197,\n",
       "                     1224,  1226,  1229,  1232,  1233,  1252,  1259,  1260,  1329,\n",
       "                     1368,  1388,  1468,  1475,  1523,  1532,  1533,  1545,  1550,\n",
       "                     1570,  1590,  1651,  1699,  1702,  1711,  1736,  1762,  1766,\n",
       "                     1772,  1773,  1780,  1799,  1847,  1886,  1897,  1914,  1952,\n",
       "                     1997,  1999,  2071,  2149,  2178,  2190,  2197,  2248,  2272,\n",
       "                     2296,  2312,  2327,  2362,  2392,  2395,  2459,  2464,  2467,\n",
       "                     2471,  2488,  2498,  2501,  2508,  2510,  2526,  2549,  2586,\n",
       "                     2643,  2660,  2683,  2728,  2744,  2749,  2753,  2808,  2821,\n",
       "                     2824,  2830,  2840,  2856,  2867,  2893,  2934,  2940,  2941,\n",
       "                     2988,  3012,  3015,  3018,  3028,  3037,  3085,  3100,  3118,\n",
       "                     3130,  3163,  3184,  3224,  3270,  3326,  3336,  3361,  3478,\n",
       "                     3482,  3485,  3506,  3533,  3547,  3563,  3574,  3587,  3594,\n",
       "                     3646,  3677,  3689,  3733,  3746,  3748,  3798,  3829,  3868,\n",
       "                     3875,  3879,  3911,  3926,  3941,  3942,  4035,  4054,  4068,\n",
       "                     4086,  4091,  4119,  4182,  4183,  4201,  4206,  4231,  4286,\n",
       "                     4299,  4316,  4335,  4384,  4406,  4480,  4504,  4559,  4583,\n",
       "                     4590,  4598,  4606,  4639,  4643,  4666,  4673,  4717,  4745,\n",
       "                     4750,  4762,  4775,  4793,  4853,  4870,  4887,  4905,  4928,\n",
       "                     4932,  4958,  4970,  5011,  5013,  5066,  5098,  5104,  5149,\n",
       "                     5179,  5206,  5223,  5224,  5225,  5239,  5246,  5305,  5308,\n",
       "                     5325,  5341,  5354,  5362,  5365,  5383,  5398,  5403,  5450,\n",
       "                     5526,  5531,  5545,  5549,  5610,  5638,  5641,  5671,  5710,\n",
       "                     5720,  5728,  5738,  5757,  5801,  5821,  5916,  5931,  5937,\n",
       "                     5944,  5958,  5963,  5966,  6015,  6033,  6081,  6083,  6103,\n",
       "                     6118,  6147,  6156,  6166,  6213,  6217,  6240,  6270,  6301,\n",
       "                     6304,  6419,  6427,  6513,  6522,  6524,  6529,  6553,  6555,\n",
       "                     6556,  6580,  6614,  6622,  6656,  6660,  6669,  6676,  6702,\n",
       "                     6748,  6762,  6803,  6813,  6842,  6882,  6907,  6960,  6964,\n",
       "                     6985,  6995,  7031,  7042,  7053,  7060,  7061,  7071,  7084,\n",
       "                     7098,  7129,  7146,  7160,  7172,  7182,  7191,  7193,  7205,\n",
       "                     7249,  7298,  7312,  7322,  7340,  7348,  7365,  7374,  7403,\n",
       "                     7469,  7480,  7534,  7543,  7572,  7608,  7635,  7670,  7703,\n",
       "                     7759,  7792,  7839,  7848,  7854,  7858,  7861,  7879,  7889,\n",
       "                     7891,  7932,  7935,  8006,  8009,  8036,  8103,  8258,  8300,\n",
       "                     8318,  8340,  8358,  8392,  8416,  8429,  8433,  8436,  8446,\n",
       "                     8468,  8491,  8492,  8509,  8512,  8524,  8525,  8534,  8540,\n",
       "                     8588,  8599,  8615,  8670,  8716,  8738,  8759,  8763,  8822,\n",
       "                     8823,  8840,  8841,  8868,  8906,  8923,  8938,  8949,  8957,\n",
       "                     8978,  9016,  9054,  9107,  9131,  9137,  9146,  9154,  9175,\n",
       "                     9193,  9221,  9233,  9244,  9248,  9252,  9264,  9276,  9287,\n",
       "                     9318,  9359,  9373,  9379,  9392,  9434,  9471,  9503,  9602,\n",
       "                     9633,  9662,  9718,  9726,  9733,  9755,  9764,  9798,  9805,\n",
       "                     9824,  9855,  9860,  9864,  9904,  9931,  9968,  9998, 10006,\n",
       "                    10030, 10033, 10091, 10103, 10117, 10118, 10229, 10240, 10244,\n",
       "                    10269, 10275, 10298, 10338, 10353, 10378, 10388, 10507, 10591,\n",
       "                    10608, 10610, 10620, 10621, 10640, 10652, 10668, 10684, 10703,\n",
       "                    10715, 10718, 10727, 10837, 10838, 10870, 10878, 10881, 10889,\n",
       "                    10935, 10963, 10964, 11087, 11106, 11159, 11197, 11228, 11233,\n",
       "                    11273, 11279, 11281, 11287, 11289, 11290, 11360, 11382, 11414,\n",
       "                    11416, 11419, 11423, 11468, 11592, 11685, 11699, 11715, 11723,\n",
       "                    11731, 11758, 11792, 11795, 11824, 11873, 11955, 11980, 11991,\n",
       "                    11995, 12013, 12030, 12052, 12054, 12094, 12099, 12118, 12130,\n",
       "                    12136, 12144, 12151, 12160, 12168, 12193, 12194, 12218, 12237,\n",
       "                    12243, 12265, 12335, 12338, 12373, 12381, 12446, 12448, 12463,\n",
       "                    12491, 12520, 12544, 12545, 12584, 12603, 12604, 12651, 12661,\n",
       "                    12675, 12678, 12718, 12727, 12791, 12794, 12814, 12817, 12824,\n",
       "                    12857, 12901, 12934, 12938, 13048, 13085, 13091, 13130, 13154,\n",
       "                    13182, 13198, 13263, 13282, 13286, 13293, 13316, 13337, 13338,\n",
       "                    13367, 13379, 13397, 13422, 13424, 13443, 13451, 13463, 13467,\n",
       "                    13520, 13537, 13572, 13610, 13628, 13647, 13654, 13686, 13825,\n",
       "                    13834, 13884, 13888, 13890, 13931, 13942, 13962, 14013, 14034,\n",
       "                    14069, 14076, 14103, 14135, 14138, 14149, 14166, 14173, 14175,\n",
       "                    14187, 14375, 14381, 14386, 14443, 14457, 14464, 14477, 14490,\n",
       "                    14496, 14500, 14505, 14531, 14555, 14578, 14592, 14605, 14672,\n",
       "                    14674, 14695, 14703, 14710, 14760, 14814, 14815, 14821, 14837,\n",
       "                    14839, 14860, 14881, 14887, 14917, 14945, 14960, 14968, 14982,\n",
       "                    15016, 15020, 15044, 15071, 15086, 15092, 15122, 15126, 15138,\n",
       "                    15156, 15176, 15194, 15265, 15271, 15290, 15291, 15324, 15348,\n",
       "                    15356, 15385, 15410, 15429, 15458, 15475, 15512, 15535, 15585,\n",
       "                    15589, 15690, 15695, 15747, 15756, 15806, 15826, 15837, 15868,\n",
       "                    15878, 15889, 15905, 15908, 15932, 15939, 16007, 16009, 16030,\n",
       "                    16049, 16054, 16070, 16093, 16095, 16129, 16158, 16212, 16215,\n",
       "                    16251, 16275, 16277, 16302, 16329, 16341, 16346, 16357, 16369,\n",
       "                    16410, 16414, 16430, 16466, 16479, 16489, 16497, 16510, 16547,\n",
       "                    16573, 16576, 16587, 16589, 16621, 16622, 16672, 16717, 16725,\n",
       "                    16756, 16773, 16782, 16809, 16819, 16861, 16862, 16902, 16939,\n",
       "                    16941, 16958, 16973, 16976, 16989, 16990, 16995]),\n",
       "             15: array([   20,    26,    35,    48,    78,   110,   135,   153,   183,\n",
       "                      188,   207,   209,   242,   249,   251,   253,   322,   328,\n",
       "                      342,   411,   422,   446,   489,   543,   580,   615,   618,\n",
       "                      623,   646,   655,   668,   669,   671,   706,   712,   715,\n",
       "                      724,   726,   753,   778,   816,   825,   834,   843,   846,\n",
       "                      865,   878,   934,   936,   943,   968,   988,   997,  1092,\n",
       "                     1097,  1116,  1120,  1175,  1177,  1191,  1193,  1204,  1220,\n",
       "                     1242,  1266,  1273,  1317,  1321,  1339,  1357,  1382,  1391,\n",
       "                     1424,  1428,  1449,  1477,  1485,  1531,  1622,  1623,  1675,\n",
       "                     1723,  1731,  1743,  1792,  1889,  1929,  1946,  1969,  1995,\n",
       "                     2008,  2019,  2052,  2088,  2111,  2116,  2189,  2206,  2208,\n",
       "                     2217,  2247,  2249,  2287,  2324,  2325,  2330,  2346,  2409,\n",
       "                     2414,  2458,  2479,  2504,  2509,  2602,  2624,  2625,  2701,\n",
       "                     2708,  2772,  2819,  2827,  2829,  2884,  2890,  2894,  2970,\n",
       "                     2980,  2994,  3009,  3030,  3033,  3082,  3149,  3155,  3309,\n",
       "                     3311,  3315,  3318,  3320,  3420,  3441,  3442,  3447,  3454,\n",
       "                     3488,  3541,  3542,  3581,  3670,  3684,  3724,  3763,  3805,\n",
       "                     3842,  3902,  3943,  3972,  3983,  3993,  4100,  4134,  4138,\n",
       "                     4141,  4148,  4166,  4188,  4203,  4209,  4210,  4233,  4236,\n",
       "                     4248,  4283,  4318,  4339,  4361,  4383,  4405,  4419,  4444,\n",
       "                     4458,  4487,  4521,  4527,  4557,  4608,  4620,  4625,  4633,\n",
       "                     4634,  4679,  4707,  4730,  4746,  4757,  4827,  4847,  4861,\n",
       "                     4877,  4891,  4902,  4910,  4913,  4959,  5004,  5006,  5026,\n",
       "                     5029,  5041,  5082,  5085,  5100,  5117,  5158,  5166,  5185,\n",
       "                     5215,  5220,  5228,  5238,  5266,  5272,  5374,  5419,  5431,\n",
       "                     5444,  5446,  5466,  5474,  5492,  5493,  5506,  5518,  5523,\n",
       "                     5528,  5582,  5595,  5654,  5707,  5715,  5743,  5755,  5809,\n",
       "                     5817,  5881,  5908,  5929,  5995,  6008,  6019,  6057,  6064,\n",
       "                     6080,  6099,  6142,  6231,  6312,  6347,  6372,  6404,  6418,\n",
       "                     6454,  6459,  6461,  6518,  6536,  6538,  6559,  6565,  6579,\n",
       "                     6596,  6632,  6666,  6689,  6725,  6737,  6774,  6831,  6851,\n",
       "                     6863,  6892,  6905,  6908,  6922,  6948,  6955,  6965,  6967,\n",
       "                     6971,  6982,  7054,  7069,  7124,  7153,  7163,  7212,  7220,\n",
       "                     7294,  7377,  7426,  7443,  7478,  7488,  7541,  7586,  7712,\n",
       "                     7760,  7794,  7884,  7903,  7920,  7964,  8019,  8020,  8060,\n",
       "                     8085,  8113,  8126,  8162,  8184,  8194,  8202,  8261,  8316,\n",
       "                     8329,  8384,  8470,  8507,  8517,  8585,  8598,  8600,  8621,\n",
       "                     8627,  8643,  8690,  8712,  8720,  8782,  8785,  8798,  8801,\n",
       "                     8835,  8846,  8908,  8958,  8959,  8971,  8991,  9006,  9100,\n",
       "                     9110,  9132,  9164,  9240,  9270,  9271,  9292,  9303,  9338,\n",
       "                     9345,  9374,  9477,  9488,  9493,  9534,  9569,  9581,  9589,\n",
       "                     9626,  9640,  9691,  9697,  9703,  9705,  9711,  9730,  9743,\n",
       "                     9744,  9747,  9759,  9807,  9894,  9908,  9912,  9930,  9942,\n",
       "                     9948,  9974,  9993,  9996, 10028, 10046, 10053, 10061, 10064,\n",
       "                    10067, 10095, 10142, 10151, 10181, 10191, 10195, 10204, 10232,\n",
       "                    10245, 10343, 10371, 10439, 10441, 10494, 10509, 10513, 10515,\n",
       "                    10516, 10532, 10543, 10561, 10562, 10623, 10659, 10664, 10677,\n",
       "                    10745, 10769, 10777, 10778, 10805, 10806, 10818, 10819, 10874,\n",
       "                    10877, 10984, 10987, 11022, 11097, 11152, 11167, 11248, 11255,\n",
       "                    11262, 11328, 11361, 11415, 11437, 11447, 11460, 11498, 11540,\n",
       "                    11552, 11562, 11571, 11577, 11626, 11651, 11660, 11663, 11692,\n",
       "                    11707, 11719, 11738, 11775, 11872, 11943, 12028, 12143, 12148,\n",
       "                    12169, 12172, 12186, 12212, 12219, 12234, 12274, 12343, 12346,\n",
       "                    12389, 12435, 12442, 12464, 12484, 12521, 12526, 12551, 12618,\n",
       "                    12677, 12686, 12715, 12720, 12722, 12797, 12826, 12838, 12855,\n",
       "                    12927, 12931, 12942, 13021, 13046, 13049, 13057, 13064, 13065,\n",
       "                    13097, 13173, 13187, 13201, 13208, 13255, 13291, 13330, 13361,\n",
       "                    13372, 13401, 13414, 13428, 13433, 13457, 13477, 13512, 13521,\n",
       "                    13557, 13606, 13621, 13648, 13664, 13669, 13712, 13773, 13797,\n",
       "                    13800, 13808, 13812, 13893, 13909, 13957, 13961, 13979, 14015,\n",
       "                    14040, 14098, 14176, 14178, 14225, 14245, 14246, 14298, 14323,\n",
       "                    14330, 14333, 14347, 14353, 14362, 14378, 14431, 14459, 14473,\n",
       "                    14485, 14537, 14573, 14690, 14723, 14728, 14735, 14742, 14759,\n",
       "                    14883, 14952, 14977, 14980, 14981, 15011, 15045, 15057, 15106,\n",
       "                    15109, 15142, 15168, 15174, 15225, 15232, 15241, 15259, 15266,\n",
       "                    15300, 15301, 15314, 15320, 15383, 15391, 15402, 15405, 15408,\n",
       "                    15425, 15433, 15472, 15537, 15555, 15689, 15692, 15715, 15721,\n",
       "                    15727, 15751, 15782, 15830, 15841, 15863, 15902, 15962, 15963,\n",
       "                    15964, 15988, 15996, 16005, 16040, 16045, 16055, 16057, 16074,\n",
       "                    16211, 16241, 16259, 16265, 16303, 16313, 16374, 16397, 16487,\n",
       "                    16498, 16539, 16565, 16595, 16613, 16627, 16653, 16656, 16660,\n",
       "                    16722, 16734, 16741, 16761, 16796, 16811, 16812, 16821, 16831,\n",
       "                    16881, 16912, 16918, 16919, 16929, 16993]),\n",
       "             9: array([   27,    33,    56,    85,   120,   122,   154,   194,   218,\n",
       "                      240,   254,   282,   283,   317,   337,   355,   384,   429,\n",
       "                      430,   476,   486,   496,   521,   578,   583,   584,   713,\n",
       "                      743,   748,   765,   811,   833,   942,   966,   980,   991,\n",
       "                     1000,  1006,  1023,  1024,  1026,  1032,  1066,  1148,  1203,\n",
       "                     1223,  1293,  1376,  1393,  1421,  1490,  1500,  1514,  1539,\n",
       "                     1574,  1578,  1596,  1605,  1642,  1686,  1708,  1744,  1774,\n",
       "                     1813,  1815,  1830,  1861,  1864,  1881,  1904,  1924,  1926,\n",
       "                     2121,  2131,  2140,  2188,  2193,  2212,  2230,  2234,  2300,\n",
       "                     2348,  2367,  2430,  2438,  2531,  2546,  2564,  2583,  2588,\n",
       "                     2596,  2609,  2617,  2627,  2640,  2645,  2675,  2690,  2713,\n",
       "                     2755,  2763,  2778,  2784,  2813,  2831,  2832,  2857,  2873,\n",
       "                     2903,  2905,  2917,  3002,  3008,  3013,  3016,  3038,  3053,\n",
       "                     3072,  3080,  3108,  3134,  3144,  3145,  3267,  3285,  3331,\n",
       "                     3354,  3365,  3378,  3389,  3397,  3410,  3450,  3457,  3476,\n",
       "                     3481,  3589,  3613,  3651,  3696,  3739,  3769,  3773,  3804,\n",
       "                     3822,  3937,  3975,  3986,  3994,  3997,  4010,  4041,  4061,\n",
       "                     4067,  4088,  4098,  4122,  4123,  4163,  4167,  4226,  4259,\n",
       "                     4291,  4370,  4371,  4403,  4433,  4459,  4526,  4611,  4612,\n",
       "                     4613,  4648,  4651,  4678,  4739,  4743,  4751,  4790,  4792,\n",
       "                     4838,  4886,  4912,  4933,  4942,  4950,  4997,  5007,  5021,\n",
       "                     5037,  5070,  5086,  5126,  5154,  5167,  5176,  5183,  5189,\n",
       "                     5253,  5278,  5315,  5343,  5401,  5441,  5455,  5464,  5479,\n",
       "                     5572,  5580,  5629,  5640,  5657,  5669,  5675,  5731,  5733,\n",
       "                     5823,  5892,  5950,  5981,  5992,  6002,  6012,  6034,  6038,\n",
       "                     6051,  6077,  6101,  6148,  6152,  6160,  6184,  6207,  6232,\n",
       "                     6250,  6292,  6308,  6346,  6354,  6396,  6409,  6412,  6426,\n",
       "                     6429,  6430,  6487,  6494,  6510,  6533,  6554,  6635,  6683,\n",
       "                     6687,  6699,  6721,  6728,  6805,  6829,  6830,  6878,  6911,\n",
       "                     6925,  7002,  7008,  7011,  7043,  7087,  7195,  7243,  7251,\n",
       "                     7265,  7277,  7292,  7318,  7325,  7399,  7449,  7456,  7479,\n",
       "                     7511,  7512,  7522,  7602,  7652,  7653,  7663,  7677,  7695,\n",
       "                     7710,  7763,  7773,  7776,  7806,  7844,  7845,  7863,  7871,\n",
       "                     7896,  7901,  7944,  7948,  7962,  7975,  7994,  8028,  8069,\n",
       "                     8090,  8099,  8115,  8129,  8165,  8211,  8221,  8230,  8306,\n",
       "                     8313,  8319,  8327,  8388,  8398,  8408,  8441,  8447,  8449,\n",
       "                     8454,  8497,  8533,  8596,  8652,  8671,  8737,  8742,  8752,\n",
       "                     8769,  8844,  8855,  8867,  8874,  8891,  8895,  8897,  8919,\n",
       "                     8936,  8961,  8989,  9027,  9069,  9130,  9163,  9211,  9217,\n",
       "                     9229,  9249,  9263,  9267,  9269,  9313,  9336,  9349,  9407,\n",
       "                     9408,  9419,  9469,  9499,  9568,  9599,  9611,  9635,  9685,\n",
       "                     9702,  9714,  9739,  9762,  9793,  9820,  9826,  9856,  9885,\n",
       "                     9888,  9919,  9927,  9969,  9992, 10104, 10127, 10194, 10202,\n",
       "                    10209, 10212, 10217, 10261, 10267, 10283, 10291, 10296, 10310,\n",
       "                    10360, 10375, 10471, 10474, 10488, 10526, 10527, 10541, 10553,\n",
       "                    10588, 10590, 10596, 10607, 10627, 10691, 10713, 10744, 10824,\n",
       "                    10853, 10880, 10890, 10912, 10981, 11038, 11040, 11058, 11060,\n",
       "                    11094, 11116, 11139, 11156, 11160, 11168, 11178, 11242, 11261,\n",
       "                    11303, 11306, 11335, 11348, 11359, 11367, 11436, 11456, 11466,\n",
       "                    11496, 11514, 11515, 11516, 11526, 11561, 11588, 11589, 11598,\n",
       "                    11602, 11606, 11661, 11724, 11742, 11755, 11814, 11825, 11832,\n",
       "                    11834, 11887, 11895, 11914, 11924, 11951, 12057, 12059, 12140,\n",
       "                    12142, 12147, 12153, 12166, 12192, 12241, 12295, 12369, 12377,\n",
       "                    12450, 12451, 12552, 12562, 12588, 12594, 12634, 12636, 12642,\n",
       "                    12709, 12738, 12748, 12752, 12789, 12810, 12830, 12835, 12837,\n",
       "                    12846, 12856, 12870, 12881, 12889, 12907, 12918, 12948, 12954,\n",
       "                    12956, 12985, 13074, 13103, 13139, 13144, 13157, 13185, 13215,\n",
       "                    13281, 13294, 13315, 13332, 13350, 13355, 13356, 13364, 13445,\n",
       "                    13449, 13575, 13631, 13643, 13701, 13706, 13721, 13754, 13764,\n",
       "                    13783, 13828, 13851, 13877, 13885, 13908, 13960, 13968, 14057,\n",
       "                    14073, 14074, 14180, 14200, 14209, 14236, 14277, 14290, 14325,\n",
       "                    14383, 14438, 14461, 14519, 14556, 14561, 14574, 14610, 14649,\n",
       "                    14668, 14722, 14741, 14752, 14756, 14775, 14783, 14795, 14843,\n",
       "                    14855, 14871, 14876, 14877, 14956, 14963, 15040, 15098, 15191,\n",
       "                    15214, 15357, 15440, 15469, 15470, 15476, 15486, 15524, 15550,\n",
       "                    15552, 15556, 15649, 15731, 15753, 15765, 15769, 15839, 15858,\n",
       "                    15861, 15872, 15885, 15907, 15910, 15911, 15913, 15952, 15985,\n",
       "                    16017, 16021, 16050, 16056, 16069, 16078, 16099, 16121, 16128,\n",
       "                    16136, 16185, 16187, 16199, 16246, 16269, 16290, 16293, 16298,\n",
       "                    16301, 16331, 16413, 16417, 16438, 16442, 16448, 16458, 16503,\n",
       "                    16508, 16509, 16520, 16534, 16545, 16561, 16650, 16682, 16692,\n",
       "                    16744, 16757, 16762, 16787, 16800, 16814, 16838, 16842, 16856,\n",
       "                    16858, 16915, 16942, 16948, 16949, 16959]),\n",
       "             5: array([   43,    69,    88,   137,   167,   226,   258,   287,   408,\n",
       "                      415,   499,   507,   568,   576,   598,   625,   707,   783,\n",
       "                      801,   803,   831,   851,   868,   944,   949,   969,   981,\n",
       "                      986,  1011,  1084,  1163,  1221,  1303,  1327,  1353,  1361,\n",
       "                     1399,  1422,  1495,  1517,  1518,  1571,  1588,  1618,  1670,\n",
       "                     1700,  1902,  1913,  1927,  1962,  1966,  2004,  2041,  2061,\n",
       "                     2080,  2103,  2151,  2171,  2241,  2292,  2320,  2350,  2383,\n",
       "                     2404,  2431,  2480,  2517,  2544,  2565,  2594,  2606,  2673,\n",
       "                     2682,  2691,  2704,  2776,  2796,  2928,  2985,  3069,  3092,\n",
       "                     3158,  3241,  3255,  3274,  3287,  3313,  3324,  3393,  3409,\n",
       "                     3411,  3448,  3459,  3480,  3517,  3559,  3647,  3653,  3672,\n",
       "                     3730,  3760,  3914,  3974,  4003,  4009,  4025,  4046,  4063,\n",
       "                     4069,  4106,  4144,  4191,  4207,  4387,  4425,  4434,  4436,\n",
       "                     4443,  4493,  4553,  4581,  4626,  4632,  4682,  4701,  4710,\n",
       "                     4720,  4771,  4776,  4777,  4920,  4941,  4947,  4977,  4986,\n",
       "                     4988,  5019,  5036,  5040,  5076,  5093,  5129,  5194,  5276,\n",
       "                     5283,  5291,  5307,  5326,  5340,  5390,  5393,  5416,  5470,\n",
       "                     5491,  5527,  5544,  5569,  5575,  5581,  5586,  5643,  5684,\n",
       "                     5700,  5735,  5754,  5795,  5826,  5865,  5978,  6007,  6039,\n",
       "                     6212,  6254,  6348,  6360,  6382,  6450,  6465,  6480,  6558,\n",
       "                     6585,  6597,  6611,  6612,  6739,  6740,  6755,  6783,  6784,\n",
       "                     6793,  6837,  6845,  6871,  6890,  6919,  6978,  7056,  7058,\n",
       "                     7070,  7101,  7156,  7185,  7217,  7230,  7235,  7247,  7252,\n",
       "                     7324,  7356,  7391,  7413,  7431,  7597,  7633,  7673,  7685,\n",
       "                     7698,  7704,  7713,  7728,  7747,  7749,  7757,  7810,  7853,\n",
       "                     7908,  7911,  7916,  7937,  7972,  7974,  8000,  8071,  8185,\n",
       "                     8187,  8224,  8225,  8285,  8288,  8299,  8310,  8348,  8363,\n",
       "                     8418,  8453,  8518,  8557,  8565,  8571,  8572,  8573,  8581,\n",
       "                     8708,  8733,  8792,  8794,  8800,  8802,  8875,  8876,  8888,\n",
       "                     8985,  9090,  9135,  9140,  9161,  9176,  9230,  9234,  9281,\n",
       "                     9288,  9314,  9348,  9473,  9500,  9587,  9594,  9606,  9610,\n",
       "                     9655,  9658,  9712,  9803,  9818,  9834,  9867,  9958,  9963,\n",
       "                    10013, 10014, 10073, 10101, 10141, 10154, 10160, 10252, 10266,\n",
       "                    10273, 10278, 10285, 10379, 10391, 10410, 10419, 10477, 10483,\n",
       "                    10484, 10503, 10536, 10564, 10602, 10654, 10676, 10687, 10812,\n",
       "                    10816, 10849, 10980, 10985, 11019, 11044, 11109, 11111, 11112,\n",
       "                    11137, 11150, 11212, 11219, 11241, 11291, 11383, 11432, 11457,\n",
       "                    11520, 11599, 11698, 11761, 11772, 11800, 11830, 11842, 11851,\n",
       "                    11897, 11903, 11942, 12038, 12070, 12074, 12104, 12105, 12108,\n",
       "                    12240, 12317, 12322, 12325, 12352, 12364, 12385, 12410, 12433,\n",
       "                    12434, 12469, 12516, 12577, 12578, 12587, 12662, 12668, 12689,\n",
       "                    12695, 12920, 12928, 12955, 12996, 13007, 13072, 13081, 13175,\n",
       "                    13204, 13210, 13256, 13265, 13274, 13304, 13320, 13329, 13387,\n",
       "                    13388, 13420, 13525, 13535, 13590, 13602, 13613, 13619, 13651,\n",
       "                    13689, 13729, 13763, 13774, 13776, 13839, 13855, 13861, 13867,\n",
       "                    13871, 13919, 13950, 13996, 14009, 14021, 14035, 14061, 14067,\n",
       "                    14124, 14142, 14153, 14164, 14181, 14207, 14247, 14251, 14257,\n",
       "                    14295, 14346, 14363, 14384, 14403, 14434, 14476, 14507, 14553,\n",
       "                    14666, 14698, 14713, 14765, 14920, 14926, 14962, 14990, 15080,\n",
       "                    15147, 15167, 15170, 15189, 15276, 15353, 15388, 15428, 15445,\n",
       "                    15483, 15503, 15523, 15531, 15612, 15687, 15714, 15737, 15778,\n",
       "                    15786, 15796, 15814, 15838, 15930, 15990, 15997, 16046, 16221,\n",
       "                    16243, 16314, 16321, 16342, 16356, 16362, 16391, 16453, 16464,\n",
       "                    16514, 16553, 16599, 16603, 16620, 16662, 16679, 16685, 16743,\n",
       "                    16808, 16823, 16857, 16971, 16996]),\n",
       "             2: array([   55,   119,   143,   149,   269,   329,   346,   406,   484,\n",
       "                      487,   495,   653,   662,   698,   754,   871,   909,   928,\n",
       "                      970,  1002,  1202,  1269,  1286,  1394,  1395,  1404,  1411,\n",
       "                     1431,  1460,  1508,  1511,  1535,  1554,  1586,  1613,  1624,\n",
       "                     1662,  1810,  1835,  1845,  1854,  1934,  2070,  2245,  2252,\n",
       "                     2253,  2286,  2385,  2422,  2472,  2516,  2581,  2605,  2629,\n",
       "                     2635,  2692,  2714,  2747,  2774,  2828,  2859,  2860,  2904,\n",
       "                     2908,  2947,  3050,  3109,  3110,  3120,  3128,  3238,  3391,\n",
       "                     3398,  3439,  3456,  3497,  3582,  3605,  3654,  3656,  3662,\n",
       "                     3749,  3859,  3897,  4000,  4008,  4145,  4152,  4251,  4266,\n",
       "                     4325,  4330,  4338,  4485,  4488,  4489,  4507,  4522,  4539,\n",
       "                     4540,  4556,  4572,  4621,  4655,  4656,  4690,  4706,  4721,\n",
       "                     4794,  4798,  4888,  4999,  5050,  5071,  5107,  5113,  5123,\n",
       "                     5171,  5233,  5299,  5381,  5433,  5481,  5550,  5678,  5682,\n",
       "                     5693,  5696,  5779,  5788,  5838,  5857,  5949,  5957,  5994,\n",
       "                     5997,  5999,  6029,  6035,  6065,  6078,  6086,  6134,  6196,\n",
       "                     6204,  6205,  6291,  6302,  6392,  6400,  6446,  6464,  6521,\n",
       "                     6567,  6574,  6620,  6814,  6895,  6944,  6990,  6998,  7030,\n",
       "                     7115,  7120,  7142,  7162,  7200,  7223,  7269,  7321,  7364,\n",
       "                     7417,  7419,  7508,  7510,  7523,  7537,  7686,  7694,  7701,\n",
       "                     7742,  7836,  7988,  7993,  8031,  8249,  8269,  8375,  8417,\n",
       "                     8457,  8485,  8486,  8536,  8559,  8594,  8628,  8636,  8700,\n",
       "                     8735,  8756,  8758,  8789,  8839,  8916,  8943,  9104,  9220,\n",
       "                     9223,  9238,  9319,  9394,  9462,  9571,  9613,  9676,  9694,\n",
       "                     9708,  9716,  9806,  9853,  9869,  9925, 10001, 10122, 10182,\n",
       "                    10235, 10386, 10493, 10504, 10510, 10523, 10548, 10552, 10692,\n",
       "                    10700, 10925, 10988, 11001, 11030, 11068, 11147, 11166, 11175,\n",
       "                    11193, 11207, 11238, 11322, 11349, 11373, 11384, 11430, 11519,\n",
       "                    11572, 11628, 11756, 11796, 11844, 12101, 12103, 12114, 12149,\n",
       "                    12170, 12185, 12249, 12264, 12304, 12308, 12350, 12388, 12488,\n",
       "                    12550, 12602, 12608, 12657, 12666, 12680, 12733, 12806, 12865,\n",
       "                    12903, 12939, 12940, 12943, 12973, 12974, 12978, 13087, 13093,\n",
       "                    13120, 13146, 13161, 13207, 13358, 13393, 13478, 13506, 13555,\n",
       "                    13666, 13870, 13895, 14007, 14023, 14112, 14141, 14192, 14214,\n",
       "                    14216, 14219, 14230, 14240, 14242, 14244, 14419, 14489, 14549,\n",
       "                    14590, 14593, 14640, 14711, 14718, 14721, 14844, 14845, 15003,\n",
       "                    15029, 15075, 15076, 15079, 15185, 15195, 15224, 15255, 15295,\n",
       "                    15299, 15305, 15308, 15342, 15349, 15401, 15432, 15434, 15452,\n",
       "                    15533, 15634, 15743, 15774, 15817, 15883, 15921, 15978, 16001,\n",
       "                    16104, 16111, 16205, 16207, 16276, 16333, 16361, 16433, 16455,\n",
       "                    16501, 16505, 16516, 16525, 16572, 16591, 16609, 16724, 16804,\n",
       "                    16879, 16891, 16930, 16935, 16987]),\n",
       "             11: array([   81,   106,   191,   230,   256,   391,   566,   628,   764,\n",
       "                     1052,  1268,  1344,  1563,  1567,  1720,  2055,  2129,  2135,\n",
       "                     2259,  2302,  2944,  2948,  3004,  3392,  3848,  3982,  4197,\n",
       "                     4205,  4235,  4287,  4683,  4922,  4983,  5055,  5204,  5331,\n",
       "                     5417,  5533,  5670,  5836,  5897,  6279,  6804,  6860,  6893,\n",
       "                     6909,  6920,  6984,  7021,  7085,  7323,  7344,  7396,  7573,\n",
       "                     7594,  7723,  7766,  8463,  8499,  8810,  8880,  8893,  8899,\n",
       "                     9093,  9177,  9246,  9990, 10078, 10559, 10725, 11017, 11748,\n",
       "                    11782, 11933, 12029, 12075, 12432, 12595, 12755, 12845, 13195,\n",
       "                    13284, 13425, 13703, 13739, 13752, 13900, 14006, 14527, 14848,\n",
       "                    14886, 15006, 15026, 15513, 15694, 16025, 16639, 16934]),\n",
       "             7: array([   89,    95,   109,   198,   250,   279,   347,   365,   472,\n",
       "                      485,   562,   571,   577,   589,   739,   760,   813,   817,\n",
       "                      841,   881,  1078,  1080,  1099,  1129,  1172,  1253,  1305,\n",
       "                     1335,  1367,  1548,  1561,  1632,  1668,  1689,  1705,  1714,\n",
       "                     1760,  1796,  1844,  1862,  1867,  1870,  1896,  1936,  2153,\n",
       "                     2277,  2279,  2342,  2386,  2463,  2482,  2568,  2615,  2636,\n",
       "                     2710,  2725,  2729,  2757,  2771,  2773,  2937,  2952,  2993,\n",
       "                     3056,  3091,  3157,  3162,  3196,  3303,  3321,  3399,  3403,\n",
       "                     3490,  3530,  3551,  3636,  3687,  3732,  3740,  3762,  3811,\n",
       "                     3824,  3833,  3846,  3853,  3857,  3874,  3898,  3934,  3953,\n",
       "                     3981,  4016,  4049,  4153,  4228,  4237,  4281,  4422,  4448,\n",
       "                     4453,  4551,  4596,  4624,  4698,  4754,  4832,  4985,  5008,\n",
       "                     5110,  5139,  5146,  5150,  5187,  5218,  5265,  5364,  5369,\n",
       "                     5599,  5609,  5623,  5708,  5896,  5921,  5925,  5971,  5984,\n",
       "                     5985,  6016,  6049,  6095,  6158,  6186,  6271,  6283,  6300,\n",
       "                     6329,  6393,  6401,  6457,  6468,  6471,  6570,  6599,  6674,\n",
       "                     6703,  6708,  6889,  6900,  6913,  6973,  7028,  7035,  7036,\n",
       "                     7038,  7112,  7132,  7143,  7151,  7204,  7209,  7332,  7338,\n",
       "                     7422,  7446,  7466,  7467,  7468,  7516,  7550,  7605,  7642,\n",
       "                     7716,  7746,  7934,  7960,  8003,  8037,  8094,  8128,  8141,\n",
       "                     8149,  8217,  8428,  8464,  8593,  8725,  8766,  8815,  8902,\n",
       "                     8905,  8963,  8969,  8984,  9042,  9192,  9259,  9274,  9299,\n",
       "                     9380,  9464,  9510,  9659,  9775,  9893,  9922,  9938,  9970,\n",
       "                    10004, 10116, 10120, 10302, 10326, 10351, 10423, 10438, 10456,\n",
       "                    10617, 10651, 10657, 10669, 10697, 10708, 10717, 10740, 10742,\n",
       "                    10773, 10856, 10911, 10926, 11051, 11078, 11136, 11196, 11224,\n",
       "                    11299, 11311, 11346, 11354, 11395, 11396, 11434, 11532, 11728,\n",
       "                    11816, 11885, 11900, 11969, 12039, 12076, 12119, 12173, 12183,\n",
       "                    12191, 12224, 12255, 12306, 12310, 12332, 12337, 12416, 12429,\n",
       "                    12437, 12518, 12589, 12592, 12620, 12628, 12711, 12919, 12953,\n",
       "                    12965, 13088, 13104, 13155, 13290, 13303, 13419, 13429, 13440,\n",
       "                    13452, 13505, 13553, 13565, 13653, 13746, 13766, 13779, 13816,\n",
       "                    13863, 13894, 13937, 13940, 13987, 14037, 14122, 14162, 14189,\n",
       "                    14202, 14300, 14338, 14407, 14417, 14432, 14479, 14577, 14587,\n",
       "                    14595, 14621, 14676, 14677, 14678, 14684, 14687, 14692, 14693,\n",
       "                    14774, 14780, 14833, 14834, 14913, 14964, 14973, 15019, 15065,\n",
       "                    15118, 15148, 15157, 15190, 15205, 15251, 15297, 15318, 15336,\n",
       "                    15344, 15416, 15498, 15500, 15526, 15628, 15648, 15667, 15758,\n",
       "                    15807, 15811, 15946, 15959, 16033, 16119, 16156, 16195, 16201,\n",
       "                    16231, 16315, 16355, 16371, 16409, 16471, 16499, 16542, 16641,\n",
       "                    16794, 16871, 16875, 16876, 16883, 16922, 16970, 16981]),\n",
       "             17: array([  118,   348,   388,   490,   894,   905,  1210,  1352,  1764,\n",
       "                     1793,  1894,  1930,  2136,  2152,  2270,  2307,  2427,  2604,\n",
       "                     2637,  2731,  3048,  3215,  3446,  3595,  3838,  4117,  4276,\n",
       "                     4476,  4505,  4518,  4520,  4605,  4615,  4644,  4734,  4765,\n",
       "                     4874,  5095,  5145,  5155,  5525,  5868,  5943,  6365,  6581,\n",
       "                     6713,  6840,  7532,  7610,  7756,  8049,  8121,  8253,  8286,\n",
       "                     8539,  8743,  8939,  9122,  9158,  9290,  9478,  9652,  9719,\n",
       "                     9868,  9937, 10040, 10126, 10272, 10347, 10392, 10397, 10418,\n",
       "                    11486, 12089, 12400, 12923, 13058, 13222, 13503, 13749, 13751,\n",
       "                    13807, 13874, 14030, 14167, 14506, 14547, 14789, 14794, 14950,\n",
       "                    14975, 15005, 15150, 15202, 15587, 15610, 15755, 16760]),\n",
       "             8: array([  181,   289,   504,   723,   731,  1064,  1082,  1104,  1454,\n",
       "                     1494,  1779,  2027,  2091,  2378,  2425,  2465,  2777,  2896,\n",
       "                     2912,  2995,  3176,  3276,  3295,  3317,  4065,  4275,  4552,\n",
       "                     4705,  5297,  5463,  5503,  5560,  5689,  5770,  6532,  6550,\n",
       "                     6665,  6841,  7415,  7890,  8136,  8214,  8336,  8431,  8625,\n",
       "                     9672, 10054, 10236, 10372, 10956, 11295, 11548, 12296, 12815,\n",
       "                    12891, 13080, 13568, 14196, 14554, 14645, 14657, 14665, 14685,\n",
       "                    15120, 15165, 15179, 15288, 15426, 15739, 15748, 16388, 16406,\n",
       "                    16431, 16705, 16885]),\n",
       "             13: array([  192,   237,   343,   378,   389,   407,   418,   431,   579,\n",
       "                      727,   741,   902,   920,   951,  1025,  1133,  1168,  1192,\n",
       "                     1196,  1301,  1341,  1343,  1377,  1438,  1462,  1472,  1559,\n",
       "                     1637,  1638,  1652,  1659,  1693,  1707,  1726,  1745,  1750,\n",
       "                     1787,  1925,  1971,  1973,  1976,  1990,  2014,  2038,  2059,\n",
       "                     2076,  2209,  2228,  2265,  2284,  2313,  2391,  2406,  2407,\n",
       "                     2477,  2524,  2557,  2573,  2589,  2613,  2680,  2695,  2699,\n",
       "                     2720,  2734,  2741,  2759,  2783,  2797,  2933,  2956,  3025,\n",
       "                     3041,  3073,  3074,  3124,  3142,  3171,  3204,  3236,  3280,\n",
       "                     3312,  3355,  3491,  3498,  3578,  3639,  3645,  3767,  3885,\n",
       "                     3936,  4006,  4011,  4017,  4019,  4020,  4032,  4048,  4056,\n",
       "                     4142,  4200,  4262,  4284,  4295,  4315,  4367,  4377,  4398,\n",
       "                     4399,  4637,  4723,  4736,  4820,  4875,  5023,  5045,  5054,\n",
       "                     5060,  5142,  5148,  5159,  5182,  5235,  5268,  5397,  5480,\n",
       "                     5496,  5745,  5760,  5793,  5827,  6031,  6046,  6079,  6185,\n",
       "                     6222,  6225,  6367,  6399,  6425,  6486,  6504,  6517,  6602,\n",
       "                     6662,  6688,  6693,  6723,  6772,  6807,  6843,  6906,  6927,\n",
       "                     6928,  6942,  6953,  6966,  6989,  7048,  7073,  7119,  7149,\n",
       "                     7164,  7177,  7224,  7266,  7400,  7447,  7475,  7524,  7615,\n",
       "                     7624,  7660,  7709,  7744,  7787,  7929,  7966,  7978,  7982,\n",
       "                     7997,  8004,  8014,  8027,  8064,  8118,  8163,  8271,  8311,\n",
       "                     8342,  8355,  8604,  8653,  8830,  8894,  8903,  8915,  8977,\n",
       "                     8982,  9072,  9074,  9083,  9106,  9136,  9328,  9335,  9352,\n",
       "                     9370,  9468,  9541,  9558,  9628,  9643,  9724,  9731,  9760,\n",
       "                     9898,  9915, 10089, 10090, 10092, 10110, 10138, 10155, 10197,\n",
       "                    10203, 10231, 10259, 10297, 10319, 10518, 10589, 10662, 10666,\n",
       "                    10735, 10765, 10782, 10847, 10908, 10949, 10976, 11000, 11033,\n",
       "                    11099, 11209, 11214, 11234, 11266, 11336, 11412, 11529, 11535,\n",
       "                    11581, 11603, 11611, 11619, 11638, 11665, 11739, 11750, 11862,\n",
       "                    11876, 11879, 11944, 11971, 11989, 12007, 12012, 12046, 12055,\n",
       "                    12066, 12159, 12178, 12252, 12256, 12275, 12303, 12356, 12439,\n",
       "                    12440, 12460, 12496, 12529, 12580, 12582, 12654, 12771, 12924,\n",
       "                    13027, 13069, 13073, 13126, 13158, 13176, 13196, 13227, 13241,\n",
       "                    13298, 13311, 13324, 13340, 13347, 13378, 13417, 13466, 13499,\n",
       "                    13564, 13612, 13614, 13683, 13709, 13716, 13809, 13850, 13917,\n",
       "                    13956, 14058, 14354, 14557, 14599, 14602, 14646, 14700, 14715,\n",
       "                    14793, 14870, 14937, 14969, 15046, 15074, 15081, 15143, 15177,\n",
       "                    15323, 15415, 15438, 15521, 15549, 15595, 15658, 15661, 15662,\n",
       "                    15701, 15710, 15808, 15852, 15980, 16012, 16038, 16053, 16117,\n",
       "                    16133, 16143, 16162, 16278, 16288, 16367, 16370, 16394, 16452,\n",
       "                    16586, 16605, 16614, 16654, 16721, 16727, 16863, 16867]),\n",
       "             14: array([  441,   523,   594,   828,  1083,  1284,  1369,  1666,  1725,\n",
       "                     1749,  1874,  1992,  2770,  3223,  3264,  3359,  3512,  3620,\n",
       "                     3627,  3638,  4677,  4749,  5025,  5436,  5644,  6032,  6094,\n",
       "                     6226,  6395,  6463,  6490,  7244,  7350,  7799,  8175,  8200,\n",
       "                     8520,  8632,  9584,  9683,  9700, 10737, 11027, 11101, 11387,\n",
       "                    11491, 11747, 11892, 11919, 12062, 12290, 12507, 12786, 12859,\n",
       "                    12884, 13078, 13345, 13662, 13795, 14104, 14159, 14237, 14351,\n",
       "                    14366, 14456, 14528, 14872, 14957, 15600, 15699, 15780, 16359,\n",
       "                    16383, 16910, 16964])})"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "dataset = train_data_loader.dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "model = PretrainModelTimmArc()\n",
    "checkpoint = torch.load(\"/opt/ml/image-classification-level1-04/model_best.pth\")\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model = torch.nn.DataParallel(model)\n",
    "model.to(torch.device(\"cuda\"))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): PretrainModelTimmArc(\n",
       "    (model): EfficientNet(\n",
       "      (conv_stem): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): SiLU(inplace=True)\n",
       "      (blocks): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): DepthwiseSeparableConv(\n",
       "            (conv_dw): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "            (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pw): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act2): Identity()\n",
       "          )\n",
       "          (1): DepthwiseSeparableConv(\n",
       "            (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "            (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): InvertedResidual(\n",
       "            (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "            (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act2): SiLU(inplace=True)\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): InvertedResidual(\n",
       "            (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act2): SiLU(inplace=True)\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (2): InvertedResidual(\n",
       "            (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act2): SiLU(inplace=True)\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): InvertedResidual(\n",
       "            (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_dw): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n",
       "            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act2): SiLU(inplace=True)\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): InvertedResidual(\n",
       "            (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "            (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act2): SiLU(inplace=True)\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (2): InvertedResidual(\n",
       "            (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "            (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act2): SiLU(inplace=True)\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): InvertedResidual(\n",
       "            (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
       "            (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act2): SiLU(inplace=True)\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): InvertedResidual(\n",
       "            (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act2): SiLU(inplace=True)\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (2): InvertedResidual(\n",
       "            (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act2): SiLU(inplace=True)\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (3): InvertedResidual(\n",
       "            (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act2): SiLU(inplace=True)\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (4): InvertedResidual(\n",
       "            (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act2): SiLU(inplace=True)\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): InvertedResidual(\n",
       "            (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_dw): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "            (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act2): SiLU(inplace=True)\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): InvertedResidual(\n",
       "            (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "            (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act2): SiLU(inplace=True)\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (2): InvertedResidual(\n",
       "            (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "            (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act2): SiLU(inplace=True)\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (3): InvertedResidual(\n",
       "            (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "            (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act2): SiLU(inplace=True)\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (4): InvertedResidual(\n",
       "            (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "            (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act2): SiLU(inplace=True)\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): InvertedResidual(\n",
       "            (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)\n",
       "            (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act2): SiLU(inplace=True)\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): InvertedResidual(\n",
       "            (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "            (bn2): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act2): SiLU(inplace=True)\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (2): InvertedResidual(\n",
       "            (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "            (bn2): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act2): SiLU(inplace=True)\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (3): InvertedResidual(\n",
       "            (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "            (bn2): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act2): SiLU(inplace=True)\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (4): InvertedResidual(\n",
       "            (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "            (bn2): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act2): SiLU(inplace=True)\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (5): InvertedResidual(\n",
       "            (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "            (bn2): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act2): SiLU(inplace=True)\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): InvertedResidual(\n",
       "            (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_dw): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)\n",
       "            (bn2): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act2): SiLU(inplace=True)\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): InvertedResidual(\n",
       "            (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
       "            (bn2): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act2): SiLU(inplace=True)\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (conv_head): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): SiLU(inplace=True)\n",
       "      (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "      (classifier): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "    )\n",
       "    (metric_fc): ArcMarginProduct()\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# initialize with a model\n",
    "match_finder = MatchFinder(distance=CosineSimilarity(), threshold=0.7)\n",
    "inference_model = InferenceModel(model, match_finder=match_finder)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# create faiss index\n",
    "# pass in a dataset to serve as the search space for k-nn\n",
    "# It take's long time (3m on V100)\n",
    "inference_model.train_indexer(dataset)"
   ],
   "outputs": [],
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "train_data_loader, valid_data_loader, submit_data_loader = MaskDataLoader(**data_loader_args).split_validation()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current transforms : None\n",
      "num_workers:  2\n",
      "No sampling method\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:688: FutureWarning: This class has been deprecated. Please use CoarseDropout\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "batch_size = submit_data_loader.batch_size\n",
    "n_last_samples = len(submit_data_loader.dataset) - (len(submit_data_loader) - 1) * batch_size"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "def imshow(img, figsize=(8, 4)):\n",
    "    img = inv_normalize(img)\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize = figsize)\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "df_submit = submit_data_loader.dataset.df\n",
    "predicts = np.zeros(len(df_submit))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "\n",
    "# df_submit['ans']\n",
    "for i, img in tqdm(enumerate(submit_data_loader)):\n",
    "    # print(\"query image\")\n",
    "    # imshow(torchvision.utils.make_grid(img))\n",
    "    samples, _ = inference_model.get_nearest_neighbors(img, k=1)\n",
    "    # nearest_imgs = [dataset[i][0] for i in samples.flatten()]\n",
    "    # print(\"nearest images\")\n",
    "    # nearest_imgs = [dataset[i][0] for i in samples.flatten()]\n",
    "    # nearest_classes = [dataset[i][1].item() for i in samples.flatten()]\n",
    "    if len(img) == batch_size:\n",
    "        predicts[i*batch_size:(i+1)*batch_size] = np.array([dataset[s][1].item() for s in samples.flatten()])\n",
    "    else:\n",
    "        predicts[-n_last_samples:] = np.array([dataset[s][1].item() for s in samples.flatten()])\n",
    "\n",
    "    # nearest_classes = [[dataset[i][1].item() for i in sample ] for sample in samples]\n",
    "    # imshow(torchvision.utils.make_grid(nearest_imgs))\n",
    "    # print(nearest_classes)\n",
    "    # break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "394it [02:11,  3.01it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "df_submit['ans'] = predicts.reshape(-1, 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "df_submit['ans'] = df_submit['ans'].astype(int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "import pandas as pd\n",
    "df_best = pd.read_csv('/opt/ml/image-classification-level1-04/submission_EfficientNet_b3_Cutout_Elastic_Transform_0831_144053_checkpoint-epoch7.pth.csv')\n",
    "df_last = pd.read_csv('/opt/ml/image-classification-level1-04/ArcMarginLoss_LabelSmoothing.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "(df_best['ans'] == df_submit['ans']).mean()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8912698412698413"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "(df_last['ans'] == df_submit['ans']).mean()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8901587301587301"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "(df_best['ans'] != df_submit['ans']).mean()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8910317460317461"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "df_submit[df_best['ans'] != df_submit['ans']]['ans'].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2     397\n",
       "1     241\n",
       "5     123\n",
       "13    111\n",
       "4     110\n",
       "7     100\n",
       "3      69\n",
       "8      39\n",
       "11     29\n",
       "0      28\n",
       "17     25\n",
       "10     24\n",
       "14     21\n",
       "15     19\n",
       "9      17\n",
       "16     13\n",
       "6       2\n",
       "12      2\n",
       "Name: ans, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "df_submit['ans'].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0     2305\n",
       "1     1958\n",
       "4     1753\n",
       "3     1515\n",
       "2     1145\n",
       "7      482\n",
       "13     462\n",
       "12     453\n",
       "6      453\n",
       "10     330\n",
       "16     329\n",
       "15     319\n",
       "9      317\n",
       "5      299\n",
       "14     173\n",
       "8      172\n",
       "11      69\n",
       "17      66\n",
       "Name: ans, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "test_dir = '/opt/ml/input/data/eval'\n",
    "image_dir = os.path.join(test_dir, 'images')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "df_submit[df_best['ans'] != df_submit['ans']]['ans'].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2     397\n",
       "1     241\n",
       "5     123\n",
       "13    111\n",
       "4     110\n",
       "7     100\n",
       "3      69\n",
       "8      39\n",
       "11     29\n",
       "0      28\n",
       "17     25\n",
       "10     24\n",
       "14     21\n",
       "15     19\n",
       "9      17\n",
       "16     13\n",
       "6       2\n",
       "12      2\n",
       "Name: ans, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "df_submit[(df_best['ans'] != df_submit['ans']) & (df_submit['ans'] == 4)]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                            ImageID  ans\n",
       "60     01ed60df34a15534443de81f062bfcdd9b373f8b.jpg    4\n",
       "119    18d1611138d046b92058e43bd2766904ae948a87.jpg    4\n",
       "264    a7f53f3fb1bef7f99de46b06e0da73b8c86f8ea6.jpg    4\n",
       "519    49900d73ebc4e7c11de80bcb8388df61160c3f77.jpg    4\n",
       "663    e571d2d2984ca45867d74ed2f5614ca6755d02ed.jpg    4\n",
       "...                                             ...  ...\n",
       "12184  27f3d78a161b1c4ef4070d2f899dd746e568523b.jpg    4\n",
       "12241  a74ec32ee6a46d1cc7046f46e418affdf9912562.jpg    4\n",
       "12245  a66bc8ad6f53ef775b5630cf3a8d871721c9a7c0.jpg    4\n",
       "12291  fd230e44677d11d833f1f124f3cfd1b27e566f4a.jpg    4\n",
       "12427  a97b9443d1233193660def5f92d29c73b197ad04.jpg    4\n",
       "\n",
       "[110 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>01ed60df34a15534443de81f062bfcdd9b373f8b.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>18d1611138d046b92058e43bd2766904ae948a87.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>a7f53f3fb1bef7f99de46b06e0da73b8c86f8ea6.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>49900d73ebc4e7c11de80bcb8388df61160c3f77.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>e571d2d2984ca45867d74ed2f5614ca6755d02ed.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12184</th>\n",
       "      <td>27f3d78a161b1c4ef4070d2f899dd746e568523b.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12241</th>\n",
       "      <td>a74ec32ee6a46d1cc7046f46e418affdf9912562.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12245</th>\n",
       "      <td>a66bc8ad6f53ef775b5630cf3a8d871721c9a7c0.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12291</th>\n",
       "      <td>fd230e44677d11d833f1f124f3cfd1b27e566f4a.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12427</th>\n",
       "      <td>a97b9443d1233193660def5f92d29c73b197ad04.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "df_submit.to_csv(\"ArcMarginLoss_FocalLoss.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "df_submit.to_csv(\"ArcMarginLoss_LabelSmoothing.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "img_set = set(df_submit[df_best['ans'] != df_submit['ans']]['ImageID'].values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "img_set"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'6f0f49f0db2c806bcada623fda06624e065b8399.jpg',\n",
       " 'ab7f1203f524ca4c189bd28fd12e3d2b29d72f91.jpg',\n",
       " 'd805e928df69a60d86e6a8b065ec50d32351f1c2.jpg',\n",
       " 'bc2ac641f3ca7ff36c99d79201066437f3ad5c3c.jpg',\n",
       " 'cf35106e1b4f9f6c7c9387e15c345e713a54d95b.jpg',\n",
       " '5239f6b4a07f3d971ed34631ae940080fe18c358.jpg',\n",
       " 'bbd595b4fb6224d770081051c162e8ac0e8c4468.jpg',\n",
       " '27ced423e752439774c023af444aed7b7ee3d68e.jpg',\n",
       " '43921d0ca4a6f3c25ea4ac2fe8b7018202354c80.jpg',\n",
       " '37ea6c80eab05dfaa49fc0a7e48c9f6aa6c1306c.jpg',\n",
       " '274eaf13b3b824df0ad899f832633f83ca9ecacd.jpg',\n",
       " 'a43df2551a7ae20937a97b419fb1ae7299251170.jpg',\n",
       " '5f48ba87d1650004d45901fb4af40afe830dc40b.jpg',\n",
       " '84679bdc8dd573f0d97e8f8130661da2f303de8f.jpg',\n",
       " 'db24141f383627414caa052e491354ca01551f8c.jpg',\n",
       " 'db5e7887deef2b0178adeb0b7f51e2041aba495d.jpg',\n",
       " 'a3edf746b0c2512bf6b70cab6913f4a02dfe47db.jpg',\n",
       " 'f77d7059181cd4cbd2c17fa578eb021711236932.jpg',\n",
       " '8fe1c1ad9f3208f3cac5a97b74a3962d03a6abcd.jpg',\n",
       " 'cff048841c8e64c482568a087c5c8f06413f2a79.jpg',\n",
       " '5e87c2ba9fec9ed9d3dc0f226feda118d6685db7.jpg',\n",
       " '5a7fbdb63d2ac96246dfbd23c1914927ada1607b.jpg',\n",
       " '8036a019983a14a586ee35b26403b97f739ef67d.jpg',\n",
       " '14aadd93035d8928311ee7c01a050f3bb968cff9.jpg',\n",
       " '6bc9cbe4c74b09f0c8647f76586dedcc15556c66.jpg',\n",
       " 'bb207dd6c714c7c16d1ca3e9754fa5c323d68d1f.jpg',\n",
       " '14053252d4b94a2083ec05a197368c008770aaaf.jpg',\n",
       " '1edae6f1aa228da3d7c475c501bd08ca5a929e6b.jpg',\n",
       " '07b7007471ef343d02686a0a957b747b64dc5fe4.jpg',\n",
       " '8a7fee241ebc64858946ede9c7ad3d6510819b51.jpg',\n",
       " 'd438d2824590f2ea5a79ab7dacdd4c30aa0ee148.jpg',\n",
       " 'c3138d74847b780fc759464f462b367e8dd2e089.jpg',\n",
       " '61286479d8ccf4057e5c42465c2ea858e1604101.jpg',\n",
       " 'dfdc964822c0bb76bd27ca829bfbb8bcdaa42c42.jpg',\n",
       " 'e910c8ba3573e9ab468b1702c8502aebafffae0d.jpg',\n",
       " '967e1fff07eb1caa13499c330ff3e396175057ff.jpg',\n",
       " '952ce52336ff426a3a7952c87281e866a40e04da.jpg',\n",
       " '6d38c75749421f5da46df9fe9f806edb0051e610.jpg',\n",
       " '1417451f3dce3b4da81627c4bd48eaa677b6bdd3.jpg',\n",
       " '2b8f2155134a8e96d3cc3956b00f13bd60ebd858.jpg',\n",
       " 'a7e6c452690aa51d02249e9d6da5b3c49b29c214.jpg',\n",
       " '9e670afa0b5363a7f3a15809b7bbda145d595e2e.jpg',\n",
       " '6b51f040c02bfad1877d1ca04cf1a9a85d401e76.jpg',\n",
       " 'b1ca455bce7bc4096eaf94d3cf7449dd9a44a49f.jpg',\n",
       " '0417ddc09193911a66e656a63398fca15309b9d3.jpg',\n",
       " '3256f4c294c7630ad5f4295a975f3a28e83766b1.jpg',\n",
       " '800fba15c9e7a0fea0bdff4facb9bdf09bc035c6.jpg',\n",
       " '0401671e6a939afe97d6c30bc820fbfe9519286a.jpg',\n",
       " 'ffe617d5115e91ad84ac19b5bd26422c6ab8e545.jpg',\n",
       " 'a5b4d19fef517a6754e3b3215c73a55374b790ca.jpg',\n",
       " 'be180f7a2b5d83be57bfc984d175c43425410bee.jpg',\n",
       " '4b3b954a70fffec3fbc9ec6dd8ebac431fd6cb41.jpg',\n",
       " '3226e23e1375d02bd48059ee2f79152da7c09093.jpg',\n",
       " '441419a874f4d031cd576850b68539ca7d35bedf.jpg',\n",
       " '53f66e78a14789d0fe768993e4b8dd583581e753.jpg',\n",
       " '6dfff604ad1d5b751623e5d93cf1a450ea0fef86.jpg',\n",
       " '7c97089a5e86966779ecf7e14659277aae2f90fe.jpg',\n",
       " '2f13b0c923ae3032ef4ca92047a180e026abea10.jpg',\n",
       " 'c266c5bb05b2ae38db54d464ec926e4521a85a90.jpg',\n",
       " 'dadebc3b8f7a116c69ee7d1b601fdbf2aba696b1.jpg',\n",
       " 'f021e0bbb183e8fb1b2d5eed0b7d8e6072486eaf.jpg',\n",
       " 'e4e832e1e429cf505c3020e8058409d166a5c0f6.jpg',\n",
       " '03e55593dc2b7399923cfd104738b83dacf8c25b.jpg',\n",
       " 'dfc828f044bc493514c1f2f3ccf7837a3201a8b3.jpg',\n",
       " '2098ab7d5c9a3bf805cd853fc31591d7f9eaf1a9.jpg',\n",
       " '27523e8e073417ea69cd8c79acd324f631a063ac.jpg',\n",
       " 'c36cbb6f1cf97a00bf687c00f171af3c4b5d088c.jpg',\n",
       " 'caed88568cf4380f515099757cba5693c83002e8.jpg',\n",
       " 'dc4a433c97ff045b82c6022eeeb577b8ffe2706d.jpg',\n",
       " 'b067c5a765a69c645168c9881953252c6f227268.jpg',\n",
       " '8c359540ce44342d62eb683c8b188daedff8f366.jpg',\n",
       " '03e89b75af1d3552f7b32844c7cc1c5dabe05240.jpg',\n",
       " '30e046a0f46904b9b55ffc1c1d2aa5d1092cdee8.jpg',\n",
       " 'c18641fb61b51ce36abfd18bdb22058d8551ced6.jpg',\n",
       " '5a4e76b8c3540380b7960e65778f2953a951f496.jpg',\n",
       " 'e9e4e69d17b0bec2247fd35a9a8d0b5d484a74d3.jpg',\n",
       " 'faca7b8f6f2b5a9b70532a5053c0b0dc6bf33468.jpg',\n",
       " 'd9314ee128657c0bde51c1f439029e3457f30135.jpg',\n",
       " '6c264b272612dbc09747132961f8a31e4d3344bf.jpg',\n",
       " 'eea1ca6dd111503eeda979a37dd18d8326bf3f1d.jpg',\n",
       " '91c9a10b83f47db7ad66fad0b5f969fbd41c744d.jpg',\n",
       " '725bd4a63cb4fb51f2bb88fc8f099d99afc49b1a.jpg',\n",
       " 'a1e108b5c6bd6d0ae9b5a07d23b23094efb157af.jpg',\n",
       " 'b4071fa59c6186461a5629bbdde2ae88a02e1438.jpg',\n",
       " '4173efac030ae4a23aececce11c3b58e83e2d091.jpg',\n",
       " '3a46cc76d1c2ab1c9cb28b5aa6583bddbc8c2841.jpg',\n",
       " 'c9fb63f8dd9a653e12964396dd7ac8dd51fbb1d5.jpg',\n",
       " '564f3422650515de43f9fe2e2362601d9b3e797a.jpg',\n",
       " '8caf6c0bdd4946b0d0fb1c3b260284f353d2c28b.jpg',\n",
       " '8fff5e4a7ffe52ad51c2416be8cbd4d214d1d5a8.jpg',\n",
       " 'eead1d16714a3e6517a1fe0079af8d3777667661.jpg',\n",
       " '7b5c08fff42d4aaee1cb72baa65e71984cb92202.jpg',\n",
       " 'd2f4aa2fc31cf6db7affc8c7a15cc62879f526cd.jpg',\n",
       " '2f0e3cbd16fd764ea585287081b72f024f6af9b1.jpg',\n",
       " '6d5c0951f9b27794e71dd8d9295b9e8d4a5341d9.jpg',\n",
       " 'c5826711ff51e965042f9b9b6dc739dfc0b2c0e2.jpg',\n",
       " '2de7e835df396754ac28095e55df5e79420a3cc9.jpg',\n",
       " '873c639234ade7b5c8a7aa547d0dc2132c7bad7a.jpg',\n",
       " 'a66bc8ad6f53ef775b5630cf3a8d871721c9a7c0.jpg',\n",
       " '9e39428023b9d8d0d6d149ef11bdb03d9d1faaa6.jpg',\n",
       " 'a91c293f0c555d99b9f6cf5511d14c12ba4f8f77.jpg',\n",
       " '862c2fe3c111a38ba6a0430337b7c7ebb9a22d6d.jpg',\n",
       " '223ced3af8364559aa21f9fed27a7e4bbbce99cb.jpg',\n",
       " '6493a4f5cb302f3a90290f3bf9d37eb348e51e9e.jpg',\n",
       " '821fade7b8d46dd31cbbbbd56ff5530545344175.jpg',\n",
       " '38bb71d16455019b7b6094dcaa08d21422a479e4.jpg',\n",
       " '5a03377f13db75a3c5bb89569699d4ab23375891.jpg',\n",
       " 'ed55b53bd9573f090abda7b7e8e1ef9497119f6a.jpg',\n",
       " '414389a5d427eaccd96fe617f0fb66650fbceffb.jpg',\n",
       " '554cbc7f9347ea1c8257106f726b8ffa6ff913fd.jpg',\n",
       " '6270019c27ee714c08e70a683c64ba6637b04a2c.jpg',\n",
       " 'fc0579d2df0c44d58b3af628bda20e9429568e1c.jpg',\n",
       " '3d3f36a35593114294dd5301226e422dc143ab9a.jpg',\n",
       " 'ad45cac5ffa0f7dea3b2d8f4cd345e172b929528.jpg',\n",
       " 'a52ba4f530f80a553554316a4f1f7442eede75f4.jpg',\n",
       " '3c7a9fa47ef65aa0afad4368d468512d7b8c7958.jpg',\n",
       " '7474cac0967e8e384f84d0b98e16ef4e082dd3c6.jpg',\n",
       " 'de9a21f978b7177ec56700df70b816a606ee4d89.jpg',\n",
       " 'c38c4c542bebacadcc68d2ea2a8a34d29741f619.jpg',\n",
       " '7891e02704fe1c4ee6822b13103cb71cd283025b.jpg',\n",
       " '739cb054e3d7f018432075146ccd22a556da5e84.jpg',\n",
       " '1afc80a9dc2986332bd3f3d4b82d7f500efb092b.jpg',\n",
       " '2899e4bd7b9c45e84ebbb4c14fa54d7253f82822.jpg',\n",
       " 'bce96db4ff3c5eaae1c530c458ba91095d3b5b92.jpg',\n",
       " '1436cb0db2d225e51dd451552a5f1149d06b5c14.jpg',\n",
       " 'ce5e81860ad574572e1c627673f618efbd741b9e.jpg',\n",
       " 'e42e9d985f76dcbe414715f5a3524abd764069df.jpg',\n",
       " 'ae9101486d912460040748d1a4ae7da2b19aa01b.jpg',\n",
       " '39ce1c69e6d62b52847c6a0e2273fa2cb7995759.jpg',\n",
       " '24f8f21ab207bbc543385431ae8318e10d40d33f.jpg',\n",
       " '1a2cce212d9112216e23bd2b2b586962b7923a3d.jpg',\n",
       " '248ac27f2fbe817a315784292b1fd09884a3aea7.jpg',\n",
       " 'dde429bfbaf53a8d285afc2f84fe0bec24d3c54c.jpg',\n",
       " '60b7ffb9656bf97b720f296a4507e4b5ba76d6dc.jpg',\n",
       " '7bc3e1c444ad53fdd216fb31482ba37ad2ca1887.jpg',\n",
       " 'fbd9562ef2f13c1bdb75ce92c4d9d50f216a8498.jpg',\n",
       " 'd67f11372df1ff081aa8437da1acf73419a85782.jpg',\n",
       " '56036c87a28920b83b4c97a2a48eb12bb3a354b1.jpg',\n",
       " 'b7b965c5f8d97730a14bd23d889dfd7077507f3e.jpg',\n",
       " 'e91fb97eb9287bfb2aa42f4e7315e6312879d851.jpg',\n",
       " 'a65a8ec61b81efc75ed5160ad6385e625a333763.jpg',\n",
       " '338e7dfac73d9a6aa668027f176112d1f5c7fea4.jpg',\n",
       " 'af8653c3e6aed23a405a09729bc9a1f244d58b9b.jpg',\n",
       " '851a821681f90a1ba6ac36ec6f8c20d6a443adde.jpg',\n",
       " '702bad9f32845a81a3252e22474f34aa3f864a37.jpg',\n",
       " 'c2f70828bd38046a41578573620c59af4b7e5443.jpg',\n",
       " 'b7ec014287c4080bd1edcfa0769c421934610056.jpg',\n",
       " '581edf9ac3ebd978fb37c3f80b3c22f1b866a842.jpg',\n",
       " 'b943ae3d87abc4ee6fe41d9a5a241864593c6001.jpg',\n",
       " 'eda17092b81de00d7807ff61772b24514d6e2199.jpg',\n",
       " '8c41e0e636341242bd9a50aa24094ffba2a77a4c.jpg',\n",
       " '0fc02390e9b9793229f3f57a8ad4b214791cb78f.jpg',\n",
       " 'f6f066ed9da22e5db128acb5c1e2b2c87883ce3c.jpg',\n",
       " '3fde87ee1f457db21e36af9c784f08c203b8956f.jpg',\n",
       " 'b4384a129e193c5d94be3c22bb4d1dbe4f046b2a.jpg',\n",
       " '7261f326ac893686591d173d04af5a67b6ecaf26.jpg',\n",
       " 'efe8d34ef94e28b412333e5927365ac9d4706a53.jpg',\n",
       " 'd48aa65e7ca37ab8fa292221c80295d52cd7ffbd.jpg',\n",
       " '22de2fc03bf54d39203596ab6ed66471d6e429ed.jpg',\n",
       " 'beeca5084fcbf1ff137be0155591486630d0989c.jpg',\n",
       " '2468811b2af0410a8b4d9361943def01f8c26640.jpg',\n",
       " 'bd6bd904b05524b0754296cf027a0c5c1d3a487c.jpg',\n",
       " '23d9c5ce97df31185a4494438d2ab9411f50ad88.jpg',\n",
       " '765d9f6c1209cbd4cff4a667b558cbc52880ce57.jpg',\n",
       " 'bb82c56c1c0e01f2dc9c7f1528f5b5b23dbd6e6c.jpg',\n",
       " '3aa6962a70f763233898c458a67c0dbe996af8b9.jpg',\n",
       " '78ad5efb8e17abe2ae339f6542a3caca83795c59.jpg',\n",
       " 'fa989be2a170b82cee7aeda979d08d813009fd90.jpg',\n",
       " 'd76e99e413bdceedeff2156a00da1cc4e64064be.jpg',\n",
       " '5e68e5faa5973a176f7b4a1ca505d4ecfa2f5ce8.jpg',\n",
       " '50fd8c05aceda5f8c56f56d01cdcee96fe00b1f5.jpg',\n",
       " 'af4671b8399de8fe51b868eef74a71cd8cd222a2.jpg',\n",
       " '01626a551aff59b797681c1ebb02adb94410b55c.jpg',\n",
       " 'a6bf4e0eaf2ba7c19239508b3f890ef9752d9e0f.jpg',\n",
       " '983f303c00ef841cb6076bb6c16ea188a563e7d2.jpg',\n",
       " '08e6e35b476c79f3b8ca5d4af13b60f912afd154.jpg',\n",
       " 'a2bd90aabbdcb03f7085514a5e02c2757df6fb91.jpg',\n",
       " '78eaabca966408089e57c76a627575235b68d6f9.jpg',\n",
       " '0af3a4f02dd5ce8fd890f9b1d8f8744efbc0ab1b.jpg',\n",
       " 'cd25a4bb581c9cf04f0477a6312702c7a35e38e9.jpg',\n",
       " 'e32f829f665fb8ee54af14ed2283c0d72313d12c.jpg',\n",
       " '6fc9f16229176bc1d5b32e40c0ec1ba5a9b9f8b2.jpg',\n",
       " '7a8953b67303ac2333153b14a492ef90af5adbdc.jpg',\n",
       " 'e723e11b83353da3ccad35f3cfc7373c0fc4470d.jpg',\n",
       " 'aae75153a61c16786e6de4c8defc2879779b6a5a.jpg',\n",
       " '1756f7707b4164ec2ab2cd92d082777ac9add81d.jpg',\n",
       " '44d9246cee6e3eff763f8364711a67627e38e857.jpg',\n",
       " '74a25495e7934ed20022cd3748c9a940b7de947b.jpg',\n",
       " 'c56a2e253935a8729e578483959d2af1b219ae19.jpg',\n",
       " '788b93101115e95a51acd72b5bbf9290c07f30ff.jpg',\n",
       " 'e881c5d28bd88fba768e3023d80210c1b3427718.jpg',\n",
       " '6fa587a5953fd4504115ae5e44db2abb4e5d645e.jpg',\n",
       " '64b06e9c15c3c47182ba7629a5851f8b9bc9c191.jpg',\n",
       " 'ebaebc52380e7f1abb950ab50e5292288d8783eb.jpg',\n",
       " '05150b1e47cdb13ca7638e9f4ab74cd7e23604d8.jpg',\n",
       " 'd50173860b085aa0f4d01d11357408892b7fb800.jpg',\n",
       " '3850846ddee5d22a14f31df3036cf011cda14a57.jpg',\n",
       " '274dcc7a0ae1c22b86939eadb953d34c459bce8d.jpg',\n",
       " '68fcab01a125670559236693f0a812e1da5086e9.jpg',\n",
       " '20266598589d8e174c117c4aa855bda68c4703f4.jpg',\n",
       " 'f21b95b4103f30ddcc77041272fbcb84b35cd95d.jpg',\n",
       " '3c52847706d9d5863d4ac8d070b0e4a157f860ee.jpg',\n",
       " '79a5c2930f951069a602bfe9dc6917a7bb2d7873.jpg',\n",
       " '4f45a2f18f2aeab489187157dc8a0446ce8a67c0.jpg',\n",
       " 'b2f7d4c653e4a5ffdc8cb43aa299a33f3da9bb2a.jpg',\n",
       " '6bf047158e16ab24083e0904c492c3c6b25e910b.jpg',\n",
       " '23a87348a4168b833614203e2f7656a173275e47.jpg',\n",
       " 'f03c4e15dd8a75506308dcf5527755745de741c3.jpg',\n",
       " '38628f128c6425e66ebea19e63676e7c89e960f3.jpg',\n",
       " 'ed19e7658762e0ac142d92d31bdafcd0d775f2d6.jpg',\n",
       " 'd785476547eccea627e171341760a83add5cd538.jpg',\n",
       " '39611a5035b4f8a9cd1c2ed5cb78c56961991fbe.jpg',\n",
       " '99e0eddee6fdc729a0a37738efc1e16c37a65e5d.jpg',\n",
       " 'd6106f25f60f5e48f52da60ad5521c1ba5ef3f28.jpg',\n",
       " '313cb1cf2c318834f92e4f54789626afbcc1450b.jpg',\n",
       " '2634cbb73e1aa0e559e402e64628fa5abc126107.jpg',\n",
       " '5712c652aba34f4ccf3c16b3b2e1d9ca9f4674d3.jpg',\n",
       " '4a45300d7bbe8557679abb2d262a84ac3a44e595.jpg',\n",
       " '0de081f5fd9d614ba745fa1efabc44917d8c0a51.jpg',\n",
       " '5cf027f037920465cc9483665cebd3ad3584a33a.jpg',\n",
       " 'e9d4b2faa684277ea5faf0f90a27e1efb68ad9fd.jpg',\n",
       " 'ee1d2cf9ce2b682a4f3eee2090e1c4d6d160d180.jpg',\n",
       " '958a3112f599868a36be93f8d5cb691b166985e0.jpg',\n",
       " 'b4a6a728d8b8cff0b4b5e21caedc7f13a2490fad.jpg',\n",
       " 'be6336ac2bced6165ca06d926d2def19c0bc24d6.jpg',\n",
       " '353206f2ae85c50cb369b30564674ec04c6cb9a4.jpg',\n",
       " '9fe2a6ae7a232018d384430f45ca7c80a92474da.jpg',\n",
       " '99b404ac6c6f1a00a4c11c530e1f0e33e0c2b466.jpg',\n",
       " 'e4b47e015f5391978cad97ceef6e8d365006db87.jpg',\n",
       " 'bc979e75fc0353d092603a9e36a22eb4b7051926.jpg',\n",
       " '70e572fa56030f1bd7e8d5fbc2551f069526e747.jpg',\n",
       " '0b169ec3247393f5a75507513361e7a896b2a085.jpg',\n",
       " 'bde6f97df1f2af382d3a251e4376be43ae363de8.jpg',\n",
       " '247e981bac31406069e3703c04f66265207c87c7.jpg',\n",
       " 'd10a71339e1baa9102184a1b1f0338c897e8ea48.jpg',\n",
       " 'ad6e3171f838123b17512abf097d70844b3698c1.jpg',\n",
       " 'c2b127ed40938de57b3ed2297101f9090ee31033.jpg',\n",
       " '0c8eccece413c661bc6bf5c436d107f082d46433.jpg',\n",
       " '42d62a775b3ffe33b53455361d8fe156f0888dfb.jpg',\n",
       " 'e4d7e738fa2666c04614a0bc5855c82e3036c9a3.jpg',\n",
       " '0ff5ea2da4de8d2b4b43b63e8e0899dcd80d3053.jpg',\n",
       " '910429f3c140956252efb8ca2fed0e764b95060c.jpg',\n",
       " '901208312075590ea6c6cae2984687276c145f23.jpg',\n",
       " '3a113efe09c7d7b15e078c3c98f3d0ff5e3c2f0a.jpg',\n",
       " 'e7e6b172a506da2f0ecad11f5903d533865ceb7b.jpg',\n",
       " 'd2dac40a634e5dad1ce0738831df6a345e2b665a.jpg',\n",
       " '0fd17e8d0f210ab6e09010b49a46f71d0e225d9b.jpg',\n",
       " 'ece76ff739264241651c8218569e1b3a710154b5.jpg',\n",
       " 'a16cd70063c0ab3d6b2e90c670107cd7d330029b.jpg',\n",
       " '2bcdddeadf8ff3fa40d2f4e9c17fcb335515efe5.jpg',\n",
       " 'c8cbc5c8d938e5ac90c04bd1a0e5e17f1c0da8e8.jpg',\n",
       " '3f792568b869a2ec02b541d7aac2d3a6391c67d4.jpg',\n",
       " 'a4d7cb7675f68d6e3b8e5aa98c68c4828d915dcc.jpg',\n",
       " 'bc54a0eb206826fabafdf3f51e61965d1abbb83d.jpg',\n",
       " '8075f930fd97d52521be5cb8a6d41a18a474e6d1.jpg',\n",
       " 'fdd5eb6e67f9f50325d93f74d76878692f75f007.jpg',\n",
       " '29bbf5ffcb8c594a3c696941e60e8d40707412b3.jpg',\n",
       " '01971a8c7fc20f8cdd60857c03c4d8417ac49cde.jpg',\n",
       " 'f992014735ecd375acb23e3e27d9c75a4335e032.jpg',\n",
       " '4af87d6cc1fa4e1e36a717ffb4d2e45ba09695a4.jpg',\n",
       " '3ed29540d09f646de2858023ca60505ffab43c92.jpg',\n",
       " '59af5bea4917a6830a76f4f29159d40232fb6043.jpg',\n",
       " '4fee2cd547b351f1c8e6a156c39be1ce834dd194.jpg',\n",
       " '5caca5904d4329e5de7f60f9cefe5297601f8170.jpg',\n",
       " 'cc5aac0b321ac369bfc779f55d8d47e99549d1ca.jpg',\n",
       " 'ee4cc02412b48953dedafc85b7bccf90f6fc0074.jpg',\n",
       " '0620ccf7bec5b28ecca1e4a90fd8f320c44102ba.jpg',\n",
       " 'df206eedad3c0e34322321252ff6acca77970e11.jpg',\n",
       " '48432b25c68030b0bf86d2fade99ea9c9df21196.jpg',\n",
       " 'c11ee928d1609ea7f38469d38af8ec57cc54db8d.jpg',\n",
       " 'e45a221a611ba59fd0f43945b9e4cb85b50d1e48.jpg',\n",
       " '866de8a1db0469b2672483de2701f9b58e0cb2fa.jpg',\n",
       " 'cfa5958b12b8bdc528cba9df2e581ae5bc45407d.jpg',\n",
       " '4cf1475de289e63556dcd7ff310b9300b699f8ea.jpg',\n",
       " 'a966e9069f37f2c338932262aaa46201fb1a9026.jpg',\n",
       " '9028e8c54f80096bf4e43390caf003f64c90e5ce.jpg',\n",
       " '57b4498ad752204edf0d69dd8d65c2dbaf8b20d1.jpg',\n",
       " '8ce40d3efb81ba5d0a760de8744d8d39744de433.jpg',\n",
       " 'efc87ed045ea79cb61fdaa1a7c98f876615bacd7.jpg',\n",
       " 'cef309f2d77f97e08d4764e1c50ca34d7ad30004.jpg',\n",
       " 'bde7aad76aad752c2ae6b262ce8ea3ca814434a0.jpg',\n",
       " '3a10fe12c1fc3950332cf8126f399feda643321e.jpg',\n",
       " 'f64765c59319466278585ad21e842be3d1f56013.jpg',\n",
       " '29db31e945ef87fbcc1d493d726559b40783f40c.jpg',\n",
       " '4c9f7faa07dbf2783bad434b4c23f567690d9e0a.jpg',\n",
       " '5ce4b5ee12eeff72e15973a4a1bf3bf5ea6cef57.jpg',\n",
       " '5d32d907240ddec9282d71736d1280823f218fc1.jpg',\n",
       " '11647eb63febd7e5b18be3927659477b0366d585.jpg',\n",
       " '2b43f4b6dbf90109af59571c1d5d792c180e7eed.jpg',\n",
       " 'b84a4f2cd9c9fca8deb07821d9db44d03308bc55.jpg',\n",
       " '23bb548f0485a2706434c186fa6a01d37a5bcaeb.jpg',\n",
       " 'f7e194c2f68c85a3bf96e1348dd8e1da75d23d9b.jpg',\n",
       " 'da226ac2be3608a6dedd0c24edfddeb982e1b619.jpg',\n",
       " '66fd7fc97c780e202cab127249048d3c7ace02dc.jpg',\n",
       " '94fcd0183a8e0a03c9354a2d5e82855529e8bdd3.jpg',\n",
       " '406716bee0f99dd5c4cb642fc575f25d866c3ac3.jpg',\n",
       " '0809d9c73b638d8a4e39a3c96c5e98fd6639aa91.jpg',\n",
       " 'aadba9dd0deab6a3719b8e65edf3304bf8ff72d7.jpg',\n",
       " '59951305bef2dd9e08f6d0d0e72bf1d98e06875a.jpg',\n",
       " 'c0448850aa5f46187160b4fe5464eea0c86f3a11.jpg',\n",
       " 'cb8a7a99db0e032698e150596c5eef2a8b861edc.jpg',\n",
       " 'f12d2abf2d3b055f5054bcb59177580359cff6ad.jpg',\n",
       " 'cf90bc8f0abadf5bcdbdc3000ead7779070894f7.jpg',\n",
       " '1b3290c6c6019fcb0d63f534963b8a69b096b04a.jpg',\n",
       " 'f1b0b10e035c2e753f8f943e427363e4fd57853d.jpg',\n",
       " '38bdf41393b3c4fd3227d8d5c93577dfd4b2ced3.jpg',\n",
       " 'd18f064dd51430248360690e24729bfd009e2279.jpg',\n",
       " 'da953843c7333fbaef168f76620be330db5192b1.jpg',\n",
       " '80b8ce85b08e4df8b8917d135154b41b51c402d8.jpg',\n",
       " '8ba4b351e07b240125ea37c461372d5e0752a5ad.jpg',\n",
       " 'f73741b1c93e67eb4f229d58f2c84854fc41b3ef.jpg',\n",
       " '4114ef201289c08ab20f7069c5d38020de7f108c.jpg',\n",
       " 'e965ddf17ebe6736d99ada1095915eda9f4e1ce5.jpg',\n",
       " '6ad40dff3b94f58512ccf449708dac7acf35f1f0.jpg',\n",
       " '41d10aa315f41f4ec013400a6d9b3762da11e577.jpg',\n",
       " '2db21d3e288b2bf3c9e81ac28b429e969895c213.jpg',\n",
       " '93ba37166ba2270c8b4d8ddd49f28e54e87300f1.jpg',\n",
       " '55448bd0c3ce678eaf736a1fc0367223fbe9d3cb.jpg',\n",
       " '490a17a269a69c2264711afc2bd491f385be1f83.jpg',\n",
       " '8511c610f5d6bad968dda6807ee1b659bc4a19df.jpg',\n",
       " '44e859caf8414457738cc72a75ea4895883ea7fd.jpg',\n",
       " '289eb11fe093f3f6ac82ba3b7e3896679dacda4b.jpg',\n",
       " 'd742c729ff4dd3f6e14815f11d9035dcd05e339c.jpg',\n",
       " '90f8ff069e31d3fe4d80058a412776e20130ed9f.jpg',\n",
       " '462566cef587ff080136cfbfb863ceac63f7f6e1.jpg',\n",
       " 'a9aebb09771569da528866939afbf3f4f5e2e4a7.jpg',\n",
       " '6240b14ac2114f87ab0fb492916579b4f9f6b6a0.jpg',\n",
       " 'd748e5d3d230fda46de506b26e32e3c7d4863ab9.jpg',\n",
       " '634b61d4aec6628ec5cfed1b49f47e1ebf4a0ed1.jpg',\n",
       " '1e849773eab81730ff55a39e22b7f03990a6aa16.jpg',\n",
       " '81bf877640e38d4f241b21ca0f50a94b21b7d6f7.jpg',\n",
       " 'ea9bd30c0dfc70ddabdd32e5cf2706016fc93c41.jpg',\n",
       " 'a0690dd9a4dc6e6bac808f95eeedcd680e057682.jpg',\n",
       " '3bab6758aff944a1dae4cb4d7aab2ffab5fe715e.jpg',\n",
       " '6889960060df3fc93f20acf86b3bed4ae8d6906a.jpg',\n",
       " '8d28372f8acf6bf003b28efcf177baf74ce79c84.jpg',\n",
       " '8d041fef59f011355a50cfc34e9b45ee1d441a00.jpg',\n",
       " '11ca1f0dea3aed3f44a99e7a900508d1f8dd88b5.jpg',\n",
       " '9925c39843d3b8589e3f7dde518d4a35114b92e0.jpg',\n",
       " 'aaba3a7300f5676cbeb797f5fa04de9ca222c98c.jpg',\n",
       " '7fa0f4f41dffd6a43a41f7f49ad5724b3abbcc6b.jpg',\n",
       " '283d7a19cee71da0c8c14940079ec69c39d8d6e1.jpg',\n",
       " 'bc13ade57ba9fd1957d3fbc7dc6d0c4f9b2d27db.jpg',\n",
       " 'fa302510c116cad97ed54aed56762aaddc26e769.jpg',\n",
       " 'bfa89b55da52976c9ab1bd92a55dc0c04f2bc01c.jpg',\n",
       " '43dab543d2d79c42fa9da3393786763560d4f992.jpg',\n",
       " '21b3ebc0b08030efc05440a2fcc5c062aab4ec7a.jpg',\n",
       " 'ecac4a564b4b0abed739ec2e021f9f6c899b4124.jpg',\n",
       " '0e2af2fa8cd5f913f4bfc2bce9906ddeb36e4211.jpg',\n",
       " 'b2e9f869e87a927bac049e73e2e40742878faedf.jpg',\n",
       " 'd55bdb561d01c4de73c22e3ce83094d7ef9ae5ec.jpg',\n",
       " 'e1138db3fdfca805486f6c7860a62d2cf2fb6296.jpg',\n",
       " 'eddce28bcabe9326128dcaa4c8e87f0e02ce1c0d.jpg',\n",
       " '2c336d59a61a33369d85699b81f275fe0d9bbd6a.jpg',\n",
       " '526ce5057e35800bd48e00b43aa394f6ea6b2268.jpg',\n",
       " '7dde3bc0b24ae90948ed52aff417a3a9fc6462b8.jpg',\n",
       " 'ee40915c997aae5462e2cd9c97df98eed4c5c367.jpg',\n",
       " '44833761f573d9cb30b460edd549cf498c694f17.jpg',\n",
       " 'de50eff8627f6389a6200c07b9f5fb912839e355.jpg',\n",
       " '18a069bc3e16c8c60bff605bab834812b49f149c.jpg',\n",
       " 'd190c3670278a6faf5d407c4e7f6eaaac3056ec8.jpg',\n",
       " '213f5df44768f21de5a07692c7dea16c9ef71749.jpg',\n",
       " 'a0bb08546ce79bfc16a7e2f4ecaeed66081b25d1.jpg',\n",
       " '86e8a59227cbda045532826e3ea1e413b667432c.jpg',\n",
       " 'be244022b293df47d8c5fac48b99c2fc446b7e2f.jpg',\n",
       " '1523d66c4a01e860fcf6e74ddf315fa0658adf53.jpg',\n",
       " '715c7a25b591e2312c3301e6e6e3b742a821362b.jpg',\n",
       " '263a9acde9c66e73c088350c6d94edb55223e50e.jpg',\n",
       " '63a6e7af80468e3d0ba67e8c5fe9c377e65a3abd.jpg',\n",
       " '89a1835cd96b673c66fc90847e154b0754ff8004.jpg',\n",
       " 'c0cda409bac201f4f9f6a5c98b0cd65a351d73b7.jpg',\n",
       " '5a7a534f3e5ac2e0d01a763575693364b47da83c.jpg',\n",
       " '3e441f54f3137cd9015a1623fca6dfc64434fd25.jpg',\n",
       " '1b993f0b720ea045f599589bdb1dfafafe11fabc.jpg',\n",
       " '788dea9ab47115accc2bb13dc2eaed9cbdfdb687.jpg',\n",
       " '0c75e40d1ee651d639ce25807a7703600aba1363.jpg',\n",
       " '7c22c97a160f5d86ba396a839ae61ce88766e819.jpg',\n",
       " 'b094d8651e98bd3e0a11889ff05ac24d7d0b5ef1.jpg',\n",
       " 'a9e3981be69df4f4aabc95d31b295f1c4637e5e1.jpg',\n",
       " 'd3991387aa1c0f02cc78689e43852abdf296efc1.jpg',\n",
       " '2e794455f8f636751952bfcb3ffdad42b10a2f13.jpg',\n",
       " '32bad9ac381240fbef65c5f9e293a66b3c08c246.jpg',\n",
       " 'e8f31f7822dab0f0bb6b04da212c64c83930ae0c.jpg',\n",
       " '6bcb6e5adfa18f6262e60196e1292dc69ac7a56b.jpg',\n",
       " 'dbbdab1ea5e650bc262fb5a2c2ef4a82e64eeeb8.jpg',\n",
       " 'f740f5a296b8d5331ae47907bd51126bb0e70697.jpg',\n",
       " 'f83d46c4af1256c10372024aa86e3ae58fc6b195.jpg',\n",
       " '6eddbd86931ec988ce9721ebb10c0c4cd46767ba.jpg',\n",
       " '84393198e225a3c212d0cefb4efc735565689371.jpg',\n",
       " '5886d34c93aa2d575504a763453490978f08108d.jpg',\n",
       " '8643108ef6ff48476a7a3bb6e448a6be2bef63c9.jpg',\n",
       " 'cd105e5a70c369bae4d76afb11d515c441fb97a9.jpg',\n",
       " 'e71ac563f03e5539c66c0fbe8b04c8c9ce1cdfe2.jpg',\n",
       " 'f239bf302af2750372355304a8fb10ee2d2ca490.jpg',\n",
       " '306d0c9d093d8cb05b5f292be9cf73a81a18e582.jpg',\n",
       " '061c982d6ec05ef4a58cb94845c2c316388794f8.jpg',\n",
       " 'efad670185a6ceb846f7a9c432a6262199b4689b.jpg',\n",
       " '02216e61bf8aa2dc414b4fcbfa5e1ba490be674e.jpg',\n",
       " 'f0e6a9809e62d23a7620e136a45343f36c98ea48.jpg',\n",
       " '14479e42fffc449e0971be2639a10fc39195e920.jpg',\n",
       " '90f1e5c30be187139dac6557a0f5a4465b27d05c.jpg',\n",
       " 'dfb43fb5e2c0981b5e1b24ba2abc2c2b4496eb38.jpg',\n",
       " '42a600be40287f991fc46f03b5d7fe733db590ad.jpg',\n",
       " '090ff46e3d6e5091c2bc557c131a772d9465f287.jpg',\n",
       " '7dbf3d552fec338f4e1a0de1de45809218102773.jpg',\n",
       " '6ea60a4dccb0c84d57da247f9b5689197944b56c.jpg',\n",
       " 'ad03ac76e2d9eb7ecf2e5d8e9c93d6c061ee0002.jpg',\n",
       " 'c90192247fbd7f74b1e141f40b650271157428f8.jpg',\n",
       " 'cfa91b0997e937c335d274488618456431d36fc8.jpg',\n",
       " '127c3eefebf43d637bff6c4fd057d149aba954eb.jpg',\n",
       " '090b3fbacc21c170f7aa098a56fa4a854c1eca85.jpg',\n",
       " '124c954e37076371cc5f902e477b021bc6c27550.jpg',\n",
       " 'e99fa6a4ad30dc4043a7eacb10c6446d1ee605e7.jpg',\n",
       " '58e35df4dffef0c24010bcb1dc5b134a373347fd.jpg',\n",
       " '3089c6c220b9c1a50b5e79a2426554ab440b55e4.jpg',\n",
       " '4dd4cb78588f220c64fd74e66fa448caf5111e33.jpg',\n",
       " '7eda14ca6e9eef3a6e792dc1073d586f021624a2.jpg',\n",
       " '130edefaaccbd2b7393ca3be689dddcf38a6c307.jpg',\n",
       " '17e9457557d92ff01a8f3c88d1532467d4a282db.jpg',\n",
       " '9fddfc15130fe3f80b465c7745f90b7bb4455f76.jpg',\n",
       " '187814f196191d1f527405aa7e8ed3185f4f9cd2.jpg',\n",
       " '99420e0ce30b8c8790e15f3dfbeb9f7307a65daa.jpg',\n",
       " '0657c449aea7f865c6f4b3f40ac8d4291b1645b3.jpg',\n",
       " '41fca78c55c70bc9d702f74016e50ecf06f6e61f.jpg',\n",
       " '587b87a3428c0715623e4250889544dd8e30e11f.jpg',\n",
       " 'a57f43d72dd6cb356a18ec10698420de72f29c6c.jpg',\n",
       " '200c837a4ab46b76779b2d7130bde480d709647d.jpg',\n",
       " '2e50d0dff60332ebaee87de4e2004c70573f2b6c.jpg',\n",
       " 'c3e8582363ceb9c1d5434f6d239aa9949157e948.jpg',\n",
       " 'f3d2965a841600cca7d0c932c0e9fe05562fb24d.jpg',\n",
       " '4423dbaff56e4c10799e5a5738796ff7baad71c2.jpg',\n",
       " 'f00a85c257893dd6628d97c579ac7c4c29253b90.jpg',\n",
       " '4909e80ddde2a704dd43194e500fa5c8292b0142.jpg',\n",
       " '0f6c42f5a49cbeb9229c50c38de06357c998ac34.jpg',\n",
       " 'a4143e58306a461a11ec883056737fb3f55e7e23.jpg',\n",
       " '5a1cce9d3226d33b38781e36205dd7ac33a00350.jpg',\n",
       " '6a889741e5b01af13ddafa7180ddc7de68811591.jpg',\n",
       " '0f522390794dd3dc769b39bd2e0f4c2b795ef483.jpg',\n",
       " 'c441fbfed86dc9ea52d7e42115314d9bb0a0c4ef.jpg',\n",
       " '2935144fe30bbb31fbcd81b269d2eed47bf3acb7.jpg',\n",
       " '02bc65d33e755cb6bfe2fcacff730212ae6ba210.jpg',\n",
       " '2ed6faca1336cee613e6b15b546c5015bcff97ed.jpg',\n",
       " '08e02c177569f045c7911b3477cfe0009ea0aa6c.jpg',\n",
       " '1e5b0a765ba3e19d3493f529e48a6ff10d5b1643.jpg',\n",
       " 'b4153b932984b4509c3e62c753d49fe240a3d544.jpg',\n",
       " '498677be4e1014bac7aef5bcfb1e14c155c73357.jpg',\n",
       " '70d1da534b881f18198c45bd1d199f9d0950932f.jpg',\n",
       " 'a2751a4a47fef77c65108edfdf62a838177a318b.jpg',\n",
       " '9945394f0641d2ef8ba44ecb4c2877843d96c11d.jpg',\n",
       " '258bb2eda66c0a3f8b59f923b1f37b364f5f67a7.jpg',\n",
       " '60259695e3ac96ce76bbcf5779da9991fdff0d06.jpg',\n",
       " '999d9b0ea9f6e9be5bfe05f9bc1970ae1cb94ae2.jpg',\n",
       " 'e501c0661677ce9cc22f3433071d58b70fb5164d.jpg',\n",
       " 'a8d4d88aad0a807f0e7d3a81ec544af022968cf2.jpg',\n",
       " '21d65abe5db4d13bf6af9f1df1a249147ed678d9.jpg',\n",
       " '6bab75f8aec8068c27228f3e27e72eaf8f51780b.jpg',\n",
       " 'a123d77cfdf3277637fb702280aca56dc1ca79fe.jpg',\n",
       " '71a6a5c0c54a21fb405175746a4dd73da2ba7f00.jpg',\n",
       " '0d18fa29f1f975f52a0c6076ebfc9226b2b928f7.jpg',\n",
       " '9c9ef14e8b3aa40c17cb93a837ecdd6613f7e681.jpg',\n",
       " 'f8206c258497969cb392245ec2e30924843623db.jpg',\n",
       " '96e048694767a89db5323032d20321e408f7df0c.jpg',\n",
       " 'e1e9058d91866a006887f7db2f8a2333cb0b0f13.jpg',\n",
       " 'f286fffc2d863b4eebe92d216b5d1ce034e9e757.jpg',\n",
       " 'ee022f48db718156bebdfee9b6d9e390c6c3f103.jpg',\n",
       " '8e433162cdb4bc995df4714b8b1c2c41ccf8f1db.jpg',\n",
       " '33598a2f3e77410e7bcc5ef6da0fca43703019a0.jpg',\n",
       " '2e0079886cbb29829d108146512100465e2014ea.jpg',\n",
       " 'a2bce44751019fd77d6ccc06796b827d177d6cbf.jpg',\n",
       " '754bcddaae919bc2fe044d4b72c3a77607c9cce5.jpg',\n",
       " 'a5f3b202930bd76f9480f9f20639c34002854161.jpg',\n",
       " 'ac221bc061d8a8a90d8620c8c8ccb910c4348c9a.jpg',\n",
       " '15b992b3547127a91484d422a0404aab0de99943.jpg',\n",
       " '44b5ab3aaeaf95c381bfdea978a7c25e25ace6ac.jpg',\n",
       " '60ac36b118b8f2042180b7a21bdca34319caab23.jpg',\n",
       " '4944c8b48751f97f9115524c74ff6485f5e70d3e.jpg',\n",
       " '5b0963236aff3bb46c191675b09633a75be274ac.jpg',\n",
       " '6cb69d232c49ce219fe9c7d41f80039e3dcf2ea1.jpg',\n",
       " '8f8faa9f3d5c8bd7f7f9fc2d4d5d3e7807fc2986.jpg',\n",
       " '3d9de6da0151852b6c123b476f1440e08bec7f0d.jpg',\n",
       " '8ebb1c61f1303e64ea46483341af6dd13e238dad.jpg',\n",
       " '60db1aafce88fe058d1a953f267a391b61e0f265.jpg',\n",
       " 'cd8c98db502ab63662c9a7b9414e6c8eb471f638.jpg',\n",
       " '0b444cf5cf16afed0b6c43ab6b6f650f6bae8423.jpg',\n",
       " '44f7d4d92709e059629d6cdd7a386bb426dd1904.jpg',\n",
       " '25c1bd574fd3ee592c7397147b7aab9eb862f744.jpg',\n",
       " 'c9014819591d4d708001b9cba977776984a59b08.jpg',\n",
       " '3a6308187a20c9f7ae3027e2b9bdfd594dda1aa5.jpg',\n",
       " 'b219962471a52249e8301d7c0b4d698e50b493eb.jpg',\n",
       " '623bc90e4d1b36590fe15e44aa13d6f355bf3a82.jpg',\n",
       " 'a273ed6cddbc6d9d96144a54bce4b17807923588.jpg',\n",
       " 'b6921bdc56513bcb13b3793298ae200671e59054.jpg',\n",
       " 'e8af9b8467c8e86d035fd260283af391eb726cea.jpg',\n",
       " '644b0ea5855cda175502c3d11096042e7e34aa08.jpg',\n",
       " 'ea8cef10e53eedc5189ff200d197688a0a1d8d2e.jpg',\n",
       " 'a675f77bf2b5a4269a35cb5a03d8453b5fc4bf25.jpg',\n",
       " '441b1bb59462f48d64df0ba665635647ed2f867e.jpg',\n",
       " 'f98b6a03a613ac459fcc65732dae0a7c8e049455.jpg',\n",
       " 'c2f808a84063bffa718bb4defa3ddb678b8aa15b.jpg',\n",
       " '357d89529df6f2ca59d260ce6ed649c8a54b75e8.jpg',\n",
       " '0bc644946b3fe4174b7ba0ba1bb7980ba9728154.jpg',\n",
       " '12bd7ba5460834991b77a2785e95bb48f8d58abc.jpg',\n",
       " '2c2469c0702361e71f79d3c8a0768c47d57c53f3.jpg',\n",
       " 'a3dedbdd991c8e5ab1f73266e64c324c947c568d.jpg',\n",
       " '0cf570e6e3fb84f13cd6c904b9c4396409776601.jpg',\n",
       " '366e1327d50327ee80c24aac778913ff6ad91f76.jpg',\n",
       " '0208194f1c357f20c32e4ee9a9d5719d73a6d0d3.jpg',\n",
       " '14b9fc3a15310bec954505ce48a86fe6d1a146c9.jpg',\n",
       " '0d782c049c42d7394a22541872758e67b71ef9fc.jpg',\n",
       " '2ad544cc536ad7e3ff6865410a2795660139785b.jpg',\n",
       " '6e8161779729166ba6b6c5974f17b3691f186b39.jpg',\n",
       " 'cc7d63257f567fcb67e4ad5688cecb57b605fb56.jpg',\n",
       " '966417b7abc8ebbb578de3adaa00d64feb7d4e98.jpg',\n",
       " '0c46ab205fd7be0e29e46214c7e7d42d2241046c.jpg',\n",
       " '43fe77f0bc4dfe368c777e0f90f95f3ce85c08ba.jpg',\n",
       " '16bee9937dd8913ce02d76b7a11d1b256820c7af.jpg',\n",
       " '202cd346b931c42c492292cdd639737904713756.jpg',\n",
       " '807e66ea017cff7df4b81e68b7db9dd76ba0922a.jpg',\n",
       " '06d438939e8ffbaf0d184fd0d89bffbe21fa848c.jpg',\n",
       " 'cfe0fb3485d45ec31b649757b7b92c79186f15a9.jpg',\n",
       " 'ea35f50a8cedcaeada32e514ccf88a109f128bf6.jpg',\n",
       " 'd38f52c48144667947bc01e15cc971014d35a73b.jpg',\n",
       " '16a321a2458872dfeec0b257be81d8d810c12239.jpg',\n",
       " '551d00108ce0bc090cf157250732423669d9723f.jpg',\n",
       " 'b9bbec2822d0af3ae164e52428aec22307146a5e.jpg',\n",
       " 'aabcc3d4cd71d8f8f11d4c484e28aa763d92bbec.jpg',\n",
       " 'cbd5e5720de3cc6669f60bfc7ad9fcbb5df21ce6.jpg',\n",
       " 'dee1053657165024c945ea7af849c6bf7751eb37.jpg',\n",
       " '8553179fef4a0001255f409f0f87e56007024699.jpg',\n",
       " '93bb42e90d31cf8bd54334f150a16520c0f46a33.jpg',\n",
       " '635cabf54f29fa60d355461ef570cca6a972062e.jpg',\n",
       " 'e203760551613d5c11ae5c54e4e9ecf353a3247d.jpg',\n",
       " 'fd230e44677d11d833f1f124f3cfd1b27e566f4a.jpg',\n",
       " 'efc17aaae4b06e9fd3e8618aa931c250dfbf7a8f.jpg',\n",
       " '9801870c1a85263cd92dfdeb4fba05668eef658d.jpg',\n",
       " '4b67411e07a6aa36aea5cc01043a5b33fd04c7b5.jpg',\n",
       " '4608636d74a2ca9bf64cc7325b9bfae544f8462b.jpg',\n",
       " '7b2be03755c4fed02fdbf90cde0ba50c5be6aff4.jpg',\n",
       " '127a5795eaed6c77621999ef19a9855495e29455.jpg',\n",
       " 'b2923f525badb8ff3be1b5856ea983691fdab3e7.jpg',\n",
       " '0a8f5f118a9f94049ee0d4207af4e2b8b98d8b11.jpg',\n",
       " 'cbd5f492c6310c8b41dc3f68487dee02c3c1fff1.jpg',\n",
       " 'fb42e713ccbc804faa4c9fe7f213a015e357edf9.jpg',\n",
       " '3f303ae260db31d0fcaa79358e5b493c8714ec1b.jpg',\n",
       " '3ec171429d0905523586b463d0738bf35c8da7ab.jpg',\n",
       " '17e7ca98cbcf9c4626a7e540aebbef18782848a2.jpg',\n",
       " '01e9a3bfdbb60edd76ea165edf37dba24611bf27.jpg',\n",
       " 'ea3af5b21c26acb279f24e835ae96d3fe93d5de0.jpg',\n",
       " '82ca622c0944cce7460b968679bf3b0c2875894c.jpg',\n",
       " '32257bd39a8bddc88495af498295f205eec01ab0.jpg',\n",
       " '4f6e673e6814c354cdbdf15d985fe06fc82fe0ae.jpg',\n",
       " '0846a90cb4e59421ca66343692248fd4fe797295.jpg',\n",
       " '812e5ed7aa409ba716e5864567ab2b2985ee63f7.jpg',\n",
       " '2194083c21b48cda6bce4d5f878afcb16434750f.jpg',\n",
       " '1a421294cc1fbb615a1726f2544917d75728e8e8.jpg',\n",
       " 'dfa355061874ec2b9e4150110d6d549fc59f50ee.jpg',\n",
       " '0def526dc39aad38f7145e25cb8b1fb4a3171348.jpg',\n",
       " '96cf32a1e36c9816e47a47a1e968b7dc4b8d1157.jpg',\n",
       " '5d64248d577896c1fe0dd78aaac3e2319f7016df.jpg',\n",
       " 'add30465c1c5f5e5b9bf1cc98a072118b918d1b4.jpg',\n",
       " '7e93e053bc645cbd0a634db68ef484abf0b59e28.jpg',\n",
       " 'b73c11cfa03639eb34324e60da98da08ad3b4377.jpg',\n",
       " '58f692674cb20497578496b1000f9900de319f14.jpg',\n",
       " '7cdc1be7e4f5cf0eec7c430b3cd4be089b181fd0.jpg',\n",
       " '4b7d88666ad2359443a8540b0503cecefd5935d1.jpg',\n",
       " '3b68e4d793dc2b78c0d6b61187b09949471c5d6c.jpg',\n",
       " '8310ea3188bda7498b6a8ceb6eeecb651f9b77cb.jpg',\n",
       " '08eac74e16b869efc9f1b71676734e6e5038de98.jpg',\n",
       " 'ef18efdb065ae0d7f967c40b20756f1a6cf457f7.jpg',\n",
       " '115d6c044d7206e0a5603f80b342e82e23f3af5f.jpg',\n",
       " '4c897cf6890691629b816d2d5a6d5a28607651f5.jpg',\n",
       " 'd14ef1216be393c6d465050fb3aef16a8c57d353.jpg',\n",
       " '13ad9d73757da883c59c5160c03fcd59da38e7fc.jpg',\n",
       " '23da1c8dd67dc7ac1fb0258a5f370f1e7f5dd381.jpg',\n",
       " 'c26724a91da94fecf87a57dc14dde46731a085e6.jpg',\n",
       " '315c1dd182589d780a0349768c979aab6ef2fc01.jpg',\n",
       " '2dbc3a4cb8de56dcf09d086e8cee16e02d7afe7b.jpg',\n",
       " '162526f43e907db7b969e764e6ec6576db449ab4.jpg',\n",
       " '671c6cead3bd5c23a066e3a8c26a26154ea5bdf6.jpg',\n",
       " '4336f9e19ab6abc94fa0613a64fc69fef751ec8f.jpg',\n",
       " '1fd1ea1be48261dc2839e3596aebbaafd49793c5.jpg',\n",
       " 'a78175a514e14bb0221ca0f56f65b97ff6b6171f.jpg',\n",
       " '9ddc2624747f938b9370d7233b8f4910d7bfa39a.jpg',\n",
       " 'aa8e7a56f68ce3af564d8c7a5ec2342f53a93e31.jpg',\n",
       " '235b6a6370b3ec3f28368f8657bace007636b2e5.jpg',\n",
       " '27f86fbbf73af0a7a53fa16651c0ea522f836bc9.jpg',\n",
       " 'e96c2e57570bbb51a718b984a2dd6b74de052709.jpg',\n",
       " '93dd372c6e123ea049b5cce2bb7fab73920978c4.jpg',\n",
       " '33dc01c880abcfa0f307d87f0e051e5154f75429.jpg',\n",
       " '848b7cbb31cd82a96d891751642c9b95290aa3f9.jpg',\n",
       " 'a4ef5c8926d5094721bd73a2814aa1a8e2bfd7dd.jpg',\n",
       " 'bd173d731f4806e5a4541fea83b1af4bc8d5a333.jpg',\n",
       " '3118993fd80f2e3e2f99ae2e6c309b58c6373190.jpg',\n",
       " '158cf8899145adc9616810a1030164d31e15caf8.jpg',\n",
       " '24ef29a3d20eec54793bee37eaf156e321374df3.jpg',\n",
       " 'd639c4a8f51ffac7e9d2bd088e49fc080952e55a.jpg',\n",
       " 'fcdadb285cfdca294e8d8d435fee340e4caf5829.jpg',\n",
       " 'dd5a58356f1a8784d90cf46ad8b0631240d40730.jpg',\n",
       " '5cbeaddbf07157a6a32d392e661ea6cc831d55fc.jpg',\n",
       " '677864308e6defac34fa072e46f1a2f3a65f2eee.jpg',\n",
       " '17081ec06a3971a1128aa600f8256d9247f3676a.jpg',\n",
       " 'f78ffb8d8bd34089b10ed64bca8e95273a9ef124.jpg',\n",
       " '8e1f6e7416208dd0036c0fe4b2524a2b7c6406f1.jpg',\n",
       " 'ff014aa14de764e9f83fcea9c5da735ab75ea5a4.jpg',\n",
       " '46dc4c6f2964a758e47de5a93ed141b442c35288.jpg',\n",
       " 'e4bb03c9fd52ab4b7545d5fc74af5fe580e487ce.jpg',\n",
       " '98d8c7e4fb1b8caec0f321882b9fd72bc99618d6.jpg',\n",
       " '6170646cd0fa76270bd690beb00fa257040512e1.jpg',\n",
       " '3bf8b3b818242b37e6d7f2d882a0a4b5dc7d995f.jpg',\n",
       " '11fe0bd69209f51e32af585264c2e40549236da0.jpg',\n",
       " '1958e5d7ad1fdae91e37b913352b96bda0f6a0b7.jpg',\n",
       " 'a97b9443d1233193660def5f92d29c73b197ad04.jpg',\n",
       " 'cf0b996d3ff2868b8db686fe89e108eea1de3cc0.jpg',\n",
       " '610453b9f9ee69d49bba896ac2d456553a852ef6.jpg',\n",
       " '0f998ab919cd0566b832415a07b7fef357a54bb6.jpg',\n",
       " '8c2bbfb95976d259fc62ffb5023fc12231bfbe89.jpg',\n",
       " '2f54985249a4b8eccf8b7b3bff9c3ea3f8b76864.jpg',\n",
       " '60288c9ce12c840a7307a82c567aa360a0c4c8c0.jpg',\n",
       " '78849d95244c607f7a738814844607669f75a983.jpg',\n",
       " 'fd5f468b1b41d726ca23719546ad5d144b3b58e1.jpg',\n",
       " '77bf870b454bc6d00128394312c67967bd77edb6.jpg',\n",
       " '5819afe32ab3515f8e61bca26ad00fe6f3a8fd61.jpg',\n",
       " '051a17a4b03e918b79173a1c2564fe660c06616b.jpg',\n",
       " 'ee3575f28afc71c8dac618e229713b74725eb319.jpg',\n",
       " '54e138ad04196f2a662599c130ea9e9ee627165b.jpg',\n",
       " 'acfb5e9c18ede13e4cdc7da0a15db777a490d782.jpg',\n",
       " 'd5886c580ed8fdadd0e79220c6830378d4ccdf62.jpg',\n",
       " 'ca3ec5bf52e43bd31e1c302140e095f61fc6f73e.jpg',\n",
       " 'fb67660ad2e4d2a9d69472d24105ef99f396913d.jpg',\n",
       " '12a431d48979eb0d160d31dd4f5dbe3ee344c003.jpg',\n",
       " 'b60b979a15b38b112dfbe6dd60e8985d1516c3f6.jpg',\n",
       " '057396bef35621555192aa7c390cf5cd095d0292.jpg',\n",
       " 'c2788f8d903557805c8b4ee56319d116f051b71f.jpg',\n",
       " '0ec02cb95ba5f1d8303df75f405d2a1ab8ea3b20.jpg',\n",
       " '3ad303ae5634658bc65ff775668320429def0a3b.jpg',\n",
       " '2853519aa637ab175ad60f43678b059262faebc3.jpg',\n",
       " 'b955cbec08251f2c8e1080266aac0396a53feac1.jpg',\n",
       " '1b602f7048352377dec4c8c48af279ba6b1f70a4.jpg',\n",
       " '8cb51f7e0dc1f8052a67209d77cebe23c76d150c.jpg',\n",
       " '1c02c8c27ce970ecb41820e954ba03fd079b59ec.jpg',\n",
       " '4dc76245b520a624e6b8a1a83a5d447f3b0f6ee9.jpg',\n",
       " '2595d984317766ee6e56005fbb96086cb1a61362.jpg',\n",
       " '97a4a32d6c1553a0295da561078350d2ed648100.jpg',\n",
       " '3f41ef438fd2257deed3f88a6c2a781864c4f281.jpg',\n",
       " 'ca9b008dfdcc37afbf43ac8b895b92fdf548e928.jpg',\n",
       " 'ba2a65474f9467aed51ee622c20ed6bab28bce9f.jpg',\n",
       " 'c70592398ebe99a9e9f251af3cc6b075995085b4.jpg',\n",
       " '96e5a6c72ebe8376e4cd80721a34e831356829aa.jpg',\n",
       " '971a04b5a86a710896c8c433ae13161e0cd8c761.jpg',\n",
       " '6a07545fa89b3ce634d501afdf87242bfb76f19f.jpg',\n",
       " '5f8a3b35fc58dc7371fc982813e0a43ca108bff5.jpg',\n",
       " '7cfbebe9e824b31cdaa14c99f1daf5d582036062.jpg',\n",
       " 'c6453d9450e5d4a02582b3c1efcacae5e8f2a009.jpg',\n",
       " 'd0d563258b3b5f93d2111163930d27648f7be897.jpg',\n",
       " 'c4470683bff2396579c2c91dbf6ba5120d2df2f7.jpg',\n",
       " '98d54297022a4c00846331f1f3a48dd632e20b06.jpg',\n",
       " '9cf728e801ade8dcbaf482ef185f0f41955dba94.jpg',\n",
       " '7acacf9b92580efc3eba62e15b7e6f5314158b23.jpg',\n",
       " 'de47b61a57a8494565ecfe9b622365a5818e963c.jpg',\n",
       " 'c193f40a51fb7f918dd7bec95c66bd4070e6f9d9.jpg',\n",
       " '7805e3e8e45aa986ba1bb77b3e0247b623ae1529.jpg',\n",
       " 'd6332e8048e4004c9fe34bef5c909dd8804a559a.jpg',\n",
       " 'f7496b04f138f12c3b32a0662c6f0111a10d739d.jpg',\n",
       " '55466dafc784032e792bae83ce6076c69f0f233c.jpg',\n",
       " '296a7ac0314823a0378d8e6f693ac40fe7f5f232.jpg',\n",
       " '9e54d9819f9898b6237315be19c01ac7e9d1a742.jpg',\n",
       " 'b18e8c07d1b4664e2c59f8bb5207c433254dcdaf.jpg',\n",
       " 'c2d68b96cc6a58d634abf9cd294ed27a3810a97a.jpg',\n",
       " 'e2581281c5b8344fcf044ce270d5a79d839a148f.jpg',\n",
       " '6247d4308dc2462c936501c5e7ac147ac39c5c9a.jpg',\n",
       " 'd283f933387f58e93ccc11a5f8d39a578b7eaa60.jpg',\n",
       " '28a19883c34e034c482c07ed6f8b972d51d94afe.jpg',\n",
       " 'fe95edefed9e6ac29b0d42b9e3302023d6701155.jpg',\n",
       " '8ed5721d0f37504a3cd83a46ca76e00592b49eec.jpg',\n",
       " '3bac8184810717bfcd4dbd1f877d5247823a2368.jpg',\n",
       " '2c66f67322ff574b113e8e5e7df1a544f5c8400e.jpg',\n",
       " '74f4b15e9b4998e2d588da2fed9cebb709c2aa7f.jpg',\n",
       " '80181e6feff4ccb72c3ab600697e9dfe17bfbd7f.jpg',\n",
       " 'a71797ee47f655ea7b76d1b895e0b271775044ba.jpg',\n",
       " 'ba18c889235455e32399775445c557dd7d39bd6a.jpg',\n",
       " '701657bb04e1d67f3a20de2923e6fc24c337e3ac.jpg',\n",
       " '99c868699b9c4523e780914a7bdf7f13e88b583b.jpg',\n",
       " '4b00cbb632aaa7fde68d25ab32655ee56786907c.jpg',\n",
       " 'b1190cd31cce39bc36e366c92a8f5e54a4ea5fc2.jpg',\n",
       " '40f014870b8f1d7fe60c51d81b61d69534336661.jpg',\n",
       " '154bb4444ec39834af39bcdbc199050a54bf8c55.jpg',\n",
       " '77ce64e403e4f766a2ca9f4ae5b51212505dcac0.jpg',\n",
       " 'f94df485923ca8f9f2702e93eaa08dabf342d9a4.jpg',\n",
       " '4e03c9d37e6f34850dee79b69cf4a22af0c3205c.jpg',\n",
       " '410e953bd0ed231400987bc90fea759ca5452eae.jpg',\n",
       " '2fd14478b022ee63b5c30a5e48274234a792d0d9.jpg',\n",
       " 'c9fab5885806f19fd4eb8ccd86607ba220990cf8.jpg',\n",
       " 'dff2f2239791fb600d5ab1d633d9c67bd72874d0.jpg',\n",
       " 'aff5d45e8a5ea12edc33f82b67e8ad14da9c0388.jpg',\n",
       " 'e6f85d97fe0ad0e313445c85589685f8430d3e47.jpg',\n",
       " 'f5fdf0e8ede4452bca4bbb0534e91fb295101f55.jpg',\n",
       " 'edc540596c42f0440a4a8b3ed3a2099362e00390.jpg',\n",
       " 'e056a947a742f62890f5b0e464702b58a7cfe42c.jpg',\n",
       " 'ee8919df75df5e107bd23d22af0f8b778713a7a3.jpg',\n",
       " '3e94e6e8ee5fb2b88cfc71df139574b65b72fbb6.jpg',\n",
       " '7915f535087ddc802e8912a19404a907a81fe5cc.jpg',\n",
       " '9debbf08f6d36fb79c752da2b878dc3eb01dd885.jpg',\n",
       " 'bf34b5b935efe9333ba4a182bf1b1de5e86df74b.jpg',\n",
       " '1d683bf76c047301b091e49360a0e96bd276d674.jpg',\n",
       " 'f97c86b75e9147ce57147617a9a58b63ed7fe2d9.jpg',\n",
       " '716b800380c5e38247c7a384bb6a31c82c9722b3.jpg',\n",
       " '6c6e315bb924b5c7e13fd36cbca5c75937992fc0.jpg',\n",
       " '4e465c24b3e458fd63ccb241dc878799df343b01.jpg',\n",
       " '636eceac0d206bda6a98389dbcb8aa821c2a5877.jpg',\n",
       " '8d77756e7065ff5f742d71f7f434393e1a7be2b4.jpg',\n",
       " '5d26246a22f6e8dab9aa9a1332502ed493720535.jpg',\n",
       " 'db9c9db6f0280c6a7bf4792318d105a7325e776a.jpg',\n",
       " '0b6c4ad748861171339170b0203a6bc7d19b01cc.jpg',\n",
       " '720755143647d23bf3228be1953fe33283b5b655.jpg',\n",
       " '081408683df382e3a75a27e6d95a7d43804717f0.jpg',\n",
       " 'ba5e6944e7037f00a30387ef4ca2fb5c46d418c6.jpg',\n",
       " '04d457bbbb027d8071c105289fbd145758fc3e39.jpg',\n",
       " '5382b116e358dd6d32bc12b845e35d4cab620bd8.jpg',\n",
       " '233bdeb12c6568a2a24cf834482bdbbd4ca0eb2e.jpg',\n",
       " '7dd81e032d5475661f79553e645d90b8fed42807.jpg',\n",
       " '01fbb208d9aaaf8093cc523038f0e50cce8909ee.jpg',\n",
       " '56ada53462a6c9706506eaab555ed2f2a2f723ce.jpg',\n",
       " '569c15fe5abfdff5ad734299bf399802fa078afb.jpg',\n",
       " '8fc057c1d405b4ba5cd0e6b5c0a552f1d7816583.jpg',\n",
       " '9b5a11f6ac17f9d1781fef6ac9dfc9061e7e5cad.jpg',\n",
       " '5c7d98ad1cd131e4e671143faeb591293e12ee6f.jpg',\n",
       " 'f2a601610ba4129356cbbe58fe691e22002c8e27.jpg',\n",
       " '71b39f3de4f44c8aabc389054960be9412a4264d.jpg',\n",
       " '6e2178aae2bb383f86416d80bf37a3bb44059abd.jpg',\n",
       " '895af1c746ee2a03e1783c9efcc2425fea60608d.jpg',\n",
       " '74c8fe557e7603951810d31e2b191770fb5702fb.jpg',\n",
       " '770d895f1374dd3e636c0235650f7523075be506.jpg',\n",
       " '74b97fc2a99ac2ac7a70bfe564aa9a1082ad7069.jpg',\n",
       " '4ba22e2d1ef164ba9745efa5d91dff53d018ba33.jpg',\n",
       " 'c7d8176ed16ec2b61977b30ab0730a92d20180b1.jpg',\n",
       " '8310538fdd000321663adc6dd1717458d0a87096.jpg',\n",
       " '894533219aab470bc0b82f3292786685e3b1bc47.jpg',\n",
       " '6796a6c42427ef81cb926c33d8e7e113228d0a1c.jpg',\n",
       " '2c739f7170efece94ddf5fb4cb46c12c4c5bbab5.jpg',\n",
       " 'b096e29cb8a400d9faf43a3c20c0b4da45a1035c.jpg',\n",
       " 'e2ee41392b3851d478cd0dd083cc23e49eb03b31.jpg',\n",
       " 'aad6b06b6b772dbd721f6943cf1edf2ec82a2303.jpg',\n",
       " '91a81be027e2de6eef98a46ff3d8a0617fb6dba8.jpg',\n",
       " '2e5e14c7c37fdd5bd1f9d48eac94ee2bbcf9408b.jpg',\n",
       " 'd1ffffc537234443bac58d588b2141f4a18513a6.jpg',\n",
       " '5e3739bd83a46a553f227585c56a362b3263a6b9.jpg',\n",
       " '108f5f7be8b45780d8966873e89012c2f1beea9b.jpg',\n",
       " 'd122a8309f99b5eaa317d7ca50b346a729f3b3c7.jpg',\n",
       " '5cf25ca9c2358296d2b3d24df04aaf2779b6011a.jpg',\n",
       " 'ea0c29cae09b8b48595e564ea97f16a930e14185.jpg',\n",
       " 'd6d18db1c6458f8cbdbfcb35bbdda35fe2adb91e.jpg',\n",
       " 'fe552db0be12309116900bc79ce014ec39c8b087.jpg',\n",
       " '54e2a397683f2ed8b2a4e218f96716c3e9559a65.jpg',\n",
       " '2a5bb495a684a315f8314f361325848abe9f04c8.jpg',\n",
       " 'b5e686e040d104c7f493c156e5aea725c6ef4e92.jpg',\n",
       " 'a741b297eaeb574517416349a3c1c40166c2b372.jpg',\n",
       " 'd32e10b137afe8733a183c51e134536ca3e8021c.jpg',\n",
       " '86c1973158069f9d6359a0c15c89c1ecc8cca1ea.jpg',\n",
       " '4f9d832379e6dc04ff4cefdc017c48c5fe8f5d27.jpg',\n",
       " '012cd908c878fa788b4dd182e32e1ac53afdf149.jpg',\n",
       " '266d12dfc28e968f7d5c201505ef4441996f0b94.jpg',\n",
       " 'a12a9794a22abdfeee96f6937504a9bc7aece672.jpg',\n",
       " 'e134ee94be4a9c8cb09b8dd3e767c90c32eab145.jpg',\n",
       " '490bc741a73f5c2220c63136a448e809a9b1bd3d.jpg',\n",
       " '188d18e37c77ba6a0d46fbcf570687b6a5fba918.jpg',\n",
       " 'a2de6f6c1b804290fbbf56122963aab98cfebb92.jpg',\n",
       " '9119b346f47d37124ba150dd97fa1ac9043b671f.jpg',\n",
       " '1fbd69ac8a5d4af43a6ef33d913370b9b2f33abe.jpg',\n",
       " 'e0a8cece16bec26ecaab92b5bbc9c96addedc066.jpg',\n",
       " '5e5d65dfdb7c7c92fea196cbe492ef58b70c51e5.jpg',\n",
       " 'ea5a3b5b7d8552b346cf37fef0f1cb657d0aabfb.jpg',\n",
       " 'f42195ec5f6eb14760a37f865abb578544d50010.jpg',\n",
       " '8625aa6e59c9c0e0e349b7b980ef0f80d17b3214.jpg',\n",
       " '09e959e050c1447280013e4f620d8f7472c26907.jpg',\n",
       " 'eab01e86b7cc00eb19dab2ee3e9f9a9181bcaaa4.jpg',\n",
       " 'cb8483f1e5d220acf3967c5353d315190cfe969f.jpg',\n",
       " '431b7b2544686bd26cf544468051624f777b2a64.jpg',\n",
       " '31cb8695549ef382edaaf2029f95b59cb664ec49.jpg',\n",
       " '776b3380b78769a0cde5c65e95958cfeee42a578.jpg',\n",
       " '3f88bd8c9747a8b40418ae331af963cfd26aa05c.jpg',\n",
       " '9af1155d243d9fb008dca808eb357aea03e5fc14.jpg',\n",
       " '27bd99571b6dddc18c52acff45b5aab8a614d4f1.jpg',\n",
       " '47e808cd3fd2d4878979002091b7d9762390193e.jpg',\n",
       " 'd81168e8221430bfbdc0027913619e88a058a8df.jpg',\n",
       " '04793eebb8b21f0de6c0680810c57e139005d33c.jpg',\n",
       " '7a2d6fc0b983702a39405e1f836e2c869bbb50c9.jpg',\n",
       " '63e4e935d4702de63deb415e5dff8e6c8c1c2dda.jpg',\n",
       " '1bcc658e8b0570d9cfab5f57db6bd2068828826f.jpg',\n",
       " '93aabd12f22e45d51f50c5507dfe6f9efd530f25.jpg',\n",
       " '8135b818bce375b76d3761a58ac11ca431159c7c.jpg',\n",
       " 'cba1b51bdc2d3c7ae8c420a581720553d194d04e.jpg',\n",
       " '97942bbbc77ec7fd71d00e83f15466ee8beb5936.jpg',\n",
       " '719d2d75d72c831d2d93ab60981b431b81dc8685.jpg',\n",
       " '42616dc870dba1ce1af12a05dbb61fad59f7aa98.jpg',\n",
       " '998ebe964e72dcf273e7e5908c31d557b85001d2.jpg',\n",
       " '8cd7549cb6c39512ddf91b8269f34d02b4419106.jpg',\n",
       " '8c6b980f85720dc3d29ad83443c9b9c1b0445070.jpg',\n",
       " 'c6b7b9ce1a00c8b2515cfe6b41e34486b38c3ca7.jpg',\n",
       " '18dd397f00c1cc8b9af02e8a78ed0fc5a9628c83.jpg',\n",
       " '2c1b239e9d976f90c3e87b9f50fac8c8e0b2d0e7.jpg',\n",
       " '23ef61214ab1bb233b491bc91e1b910288524055.jpg',\n",
       " '823dbb6f6aec2430b6aa3a63f89dcdfa55eefcf4.jpg',\n",
       " 'cdece18413efcf2058a4b5ff625c1013db646e8f.jpg',\n",
       " 'dd7ad29330a9670cf347ea58af6d873b86dafa3c.jpg',\n",
       " '482571b692ea8b5df121a3e32b2389e411e5e5ef.jpg',\n",
       " '153bc6f1e6759cf2f5694409381f84f1f98c0622.jpg',\n",
       " '71d91858b2e4ed6b0a1968f43f4d68ff8f299139.jpg',\n",
       " '685ae116998b31f7422e84ee37380c281a331672.jpg',\n",
       " '65e77c6e671c5b28c6877469835bac2a5877e6e5.jpg',\n",
       " '10f1eaab9f68a5c9f8d061755c579e7118341504.jpg',\n",
       " '587020424ac9cac04e9f3a93fea0e52663a7335a.jpg',\n",
       " '123e85dc56883513dd08db5a17e061a7ba32f1eb.jpg',\n",
       " '9ea562d45af1c854967e6abe5ff7fb368e3da583.jpg',\n",
       " '8632000bd01965700b16d8904af3fc56e36758c9.jpg',\n",
       " '6082ffef669c08e4ac9868e4d8df5d98e99c587d.jpg',\n",
       " '1ac591d3388ea4d661a0716a7d9a30955d288404.jpg',\n",
       " '60a09bfd989520efb09e6e85ebc87f624148f480.jpg',\n",
       " '1d7458ed532af30a9459185390483c0f8b41553b.jpg',\n",
       " 'b49a2858e321ff03d4b2bcbc36c010b701da8067.jpg',\n",
       " '043e0882add631c6c8f4619f7d3fadadc310eb57.jpg',\n",
       " 'c038adc436990da6cfc06b54c27683d4b9dc5620.jpg',\n",
       " 'a7f53f3fb1bef7f99de46b06e0da73b8c86f8ea6.jpg',\n",
       " '911ba4d70d5c2e0788aa8cbdd451e329a3af130d.jpg',\n",
       " '0e6f27b88bffe8d71c05599bd6de5d0dc6520314.jpg',\n",
       " '6ba661a52dae241d7551788b27ff3f4ca7dbe624.jpg',\n",
       " 'dfe91f59aea944eec32d80dcd13152f352601305.jpg',\n",
       " 'f776f4cc7ad59fb61e8cfe190ed110fd8ade2688.jpg',\n",
       " 'b35649d18e7f76cca99819936f748f66bab82da4.jpg',\n",
       " '43b967beab8dee3ac29b4293310feffa29455a2f.jpg',\n",
       " 'd1d6df339d9300a2ce0c4292f004024ce15e688c.jpg',\n",
       " 'a61dad48afaf4be70ef98a14d02c363eea7b4d5b.jpg',\n",
       " 'cd8bc581a01b444da189eca108ae17ac65405c24.jpg',\n",
       " '7463f44e99549a48dc595b65187326d3742da1fb.jpg',\n",
       " 'ea64667d294dfafa57827084a1e76ab82376946a.jpg',\n",
       " 'e31aff39169caac566a9e53ce37db934b8b08b70.jpg',\n",
       " '75ab3e57d1c5027506a50cb89ff5aa255ffa4f15.jpg',\n",
       " '289cba966b77438f747b5cc2108ea4a588dffc8c.jpg',\n",
       " 'a6b86c2e282a58d8e99b3ab990a7b37375f74911.jpg',\n",
       " 'ee951ce29e4bf99e71627098e327f6847246320d.jpg',\n",
       " '3f96f8614cf46609de32aac14a5adab05aca3eba.jpg',\n",
       " 'be455126a477f93da9464ddb792ddf343b05123c.jpg',\n",
       " '889a9c0a93a3e165ec08a35c9750ba5918abb013.jpg',\n",
       " '79b216756859962da933a38f510b0b6c6bba7597.jpg',\n",
       " '0fe92cbef795aefdd9c3ca7730e2e298b43fa5fe.jpg',\n",
       " 'd480bd187cba41133df1dfb346d765aa5d16cb19.jpg',\n",
       " '9808b80f6a7be83b6641f88a16dcaaf330828f9b.jpg',\n",
       " '6634be838ede87f727a522909c779b21d45ac61c.jpg',\n",
       " '27e8bc292e95984120a8cb189435fd18390133dc.jpg',\n",
       " 'b543e1332292f20f6875fe0e9ed3aa3b48dc9394.jpg',\n",
       " '9732f0aa4824c2ea08426bff86bcc957234a5dbb.jpg',\n",
       " 'df1743e302ed33e7163888e2c6419b0cb763cd59.jpg',\n",
       " '7ccb0396edb9c7675839ad50f689c87c8689f436.jpg',\n",
       " 'd062b6384301848a0df95c628bc0aa5d96505a4f.jpg',\n",
       " '1ccce1b9809cd84043aacd4fa669f4be28a183bf.jpg',\n",
       " 'e584a2738f175d25bf5a91a03a89be2c70bc741d.jpg',\n",
       " 'c44aae496d31ae05ab715ae919cbb0083ae28d50.jpg',\n",
       " 'e0a22b1248e396cb6e6b3421a46595bac41f2c14.jpg',\n",
       " '7497446b44127325b13246b6909fced42a4522be.jpg',\n",
       " 'd508c17dfacd6b66f8a6dfc87a01dbf06b140f44.jpg',\n",
       " 'bba586d2aacf03113478a1e7865eebb5533a55f4.jpg',\n",
       " 'c149185a1a21c8221cbba2ba03a486333d3bc247.jpg',\n",
       " 'e7a8f001ddb66fe3fbb22208e860aec86c5bc56a.jpg',\n",
       " '5e25f2a42e78a8e43a9a11569201d5aeba805487.jpg',\n",
       " '4383ec562530dc9263e6590b39a24675d9088366.jpg',\n",
       " 'a7db26cbb0f8a8e483ea78f93f73a9c649631fe3.jpg',\n",
       " 'a8dbe6352b19d3bb747d10a30013129c509a4388.jpg',\n",
       " 'ecb1901202994f4a45733989e7c321f948cae3e5.jpg',\n",
       " 'a7f46f19b6b0ac6280ffcac8acc095ff3f04f6be.jpg',\n",
       " '4049da2a05c179eaa277681e108ddff6ad790dc5.jpg',\n",
       " '49f199f2b82a546370bc8b84827e95a2c12c7fb9.jpg',\n",
       " 'a70f7cf124d340821459aef96e735a0ae726edc2.jpg',\n",
       " '6376df6489d425524eca972d1921ff1063febd75.jpg',\n",
       " '7d795173c5661acbd2668fd24657aea8dd7074cc.jpg',\n",
       " '5ea8fab35e1fb597bde3ade73054230183c7b373.jpg',\n",
       " '0cbaebb4a518f31fa481c2fbddac3ae678cdfbf2.jpg',\n",
       " 'd5038ead379dfd7d7e7bed1a8b84068f94ecfe7d.jpg',\n",
       " 'df16785cd8810e7559bf490394c5ca34a7756901.jpg',\n",
       " 'a3616c5485502836d8959a8945ee2a38299902c3.jpg',\n",
       " '1f18163897e3e1b5f073a0a7b420faa69ca718a7.jpg',\n",
       " '90a67c1df5a057dbb7c15320a5fdb809eafd0593.jpg',\n",
       " '5a7801cb2979000fb88a8adcce7439966e52a545.jpg',\n",
       " '0ce36ae42d3f0bad99c8105d2a995c04f493acf3.jpg',\n",
       " '1ff7b512a14f96ab4eea552513609391c7c8f2af.jpg',\n",
       " '1bc134ad663988d6563bbf8e1e0c17fc105c275f.jpg',\n",
       " '9dae7fae314c78ecb1fa30bbac2f5f4ad9003f80.jpg',\n",
       " '96c243e4a2615cc9b319a11ce82c5db17652ba22.jpg',\n",
       " '309c97024924aa08bbd77c7dcdbd06c78c487308.jpg',\n",
       " '1b85786d881e0bf8807053bd4c6d0d6659dace26.jpg',\n",
       " '781ed190292730a919e4ccc9d4a90ca953adf1a9.jpg',\n",
       " 'a6833f34354890c2153bd14cf798dfea1fbe0bc6.jpg',\n",
       " '9da5ae3d63373e1e44e9a323d17779f2b661e50d.jpg',\n",
       " '945f8d669bb187d5aadef42e5ff18ad2467752c4.jpg',\n",
       " 'e2ccfa3a78db46a46a8d85adbc0fe12d3a1ce333.jpg',\n",
       " 'f4928aa612b00c9dc52d72b3af6a5cd6624980c6.jpg',\n",
       " '98600f6550188a208a997d9b80ae51f86c7da960.jpg',\n",
       " '0bdd7dacc971c87bdf66da7de99762ffdf315b83.jpg',\n",
       " 'd671de08a74f9554720ba7e430848ffbd4c22840.jpg',\n",
       " '242ae930d648428c71cf72ea25fa977415d92d0a.jpg',\n",
       " 'fa65af9689edcfd38cf2822e4611a544c7af43bf.jpg',\n",
       " '26a8ff57293a2fa07ec897586662d26c4e28bd47.jpg',\n",
       " '9e6de0df768bd5418b8f3a4ad044067115e24e70.jpg',\n",
       " '439a6d5478c9ff1755f0300f0b5f621dca8d1f78.jpg',\n",
       " 'cbb0ff729caae7e58def8b6057c2af8a7608c89c.jpg',\n",
       " '88384b76cf7baa74dd2086fec1f9e0f0385a986a.jpg',\n",
       " '141434f3a204c0f5673e8805080c76bdab633693.jpg',\n",
       " 'b4139f83f461846d3992fa4f7777d1eb2654f693.jpg',\n",
       " '098cbc78a7b044ef1e6e207cbf109cbd3abd95c4.jpg',\n",
       " '62edef7e886759fb590cb6a89018874d80e4ad04.jpg',\n",
       " '7ad4d8741e7be14ca86e15d7467f2e04024760b1.jpg',\n",
       " '4466561e36c01af5d1866ffda5044cf9a21e185f.jpg',\n",
       " '0069d7d7b1e686dea02f403b7c25a8048c3ee9a2.jpg',\n",
       " '8ef9482e2a74bb05505e600b79546baf0e382922.jpg',\n",
       " '5bc44a5899c3ab390cd794832f8ff6f48ea0f802.jpg',\n",
       " 'b5cd0fc65b8ee682ecf058b587281e497e14da24.jpg',\n",
       " '0a6f8bb8ded222072206016bd3572ccfca853cf6.jpg',\n",
       " '8ac34df84b8426cdf75fed5f645c85b7bcd2d37c.jpg',\n",
       " 'c8fb2c3122372712d590dbd10270d18dc73200d4.jpg',\n",
       " '006d9819270764f5fca3fb1201c952c535b6c733.jpg',\n",
       " 'ae5c02c9bf5564216a22f487f585e733ec7f155b.jpg',\n",
       " '1420655c2a25c8cc7673eebe87dc43e67bfe1c99.jpg',\n",
       " '21212a3997934f8a882638fcdf11456cf7dab560.jpg',\n",
       " '7f6a749b513a41e66f1da4acec8f12aa459ae5a2.jpg',\n",
       " '5b6435cfdec87d750b11ff3dcb566aa0f4dc037b.jpg',\n",
       " 'f85244147784d2c5af8f73673acc583b697d8e6a.jpg',\n",
       " 'f79ef92c23b359e5d182d125ed0f417342a52bcd.jpg',\n",
       " '468a61bee5c29233618f81f7a3f6d68891a5ed91.jpg',\n",
       " '3d72ec83e32aa8ff62c4ff0cc7738d80e01ca8ff.jpg',\n",
       " 'acc002d169e9b99e88a3bd30dcdc6a3c27b8e134.jpg',\n",
       " 'ec435c14505f9647f0b2a70ed38b56adeff58ba8.jpg',\n",
       " 'fe7f2b369f1bfdab721c1a0f57b05dad8e6bdd19.jpg',\n",
       " '1acc15c8fd003d3e798a710670eff69c57b1c8c9.jpg',\n",
       " 'b1b1aa65544324d9ebc89b3deb4a714f4d1d7ea3.jpg',\n",
       " '386b4be5298795cc2905ada69cc4f69a896f0143.jpg',\n",
       " 'bfe48cf031969a5978246e23c109219afbfb13c2.jpg',\n",
       " '9316215bc2b91ec182d1ba32025734d1832c49d2.jpg',\n",
       " 'd418eea7d9b5ffce1e06c97d6f6e916992f46fb2.jpg',\n",
       " '9e0541b9b036c9aa728bc285c3c266d5332af6e5.jpg',\n",
       " '0d15d006e2ad9b148f38b75e3f486fdd66bea590.jpg',\n",
       " '9378325451fc7faa4051dbda159c1853308f57ea.jpg',\n",
       " '7ecd64a78515ecfa24544675578de73e848eae90.jpg',\n",
       " '2981b657f2957ea397f2bf2cd005cb0ba5477ed7.jpg',\n",
       " '42b1aff8f7154b9de5777c692c55383f12ad217d.jpg',\n",
       " 'beecaecf2fce950941298cf8c75474db1a5fb3c4.jpg',\n",
       " 'c2154756d48ba7125f088b8896aeffe92de2a35b.jpg',\n",
       " 'c830eea247e77497c095aad6fc40feecad673c98.jpg',\n",
       " 'c1d9df52196b3ac22d42bee7eebd2eb1ead801ba.jpg',\n",
       " '77b5a2015768d60486140c0972e306d9aa100dd2.jpg',\n",
       " '92cc271d67e119e7f55510a541cf4560657d13b0.jpg',\n",
       " '76356987883e47ae2792b17bcf1a5e1e98087f27.jpg',\n",
       " 'b0884208c546dff39f29b59052194f92f7426c29.jpg',\n",
       " '27ba8ec325fb0aad68a6bf44517de7c2a5b9ac3f.jpg',\n",
       " '4b7483a3a876f11a38076c0fafc7ffd508f1b919.jpg',\n",
       " 'ec4684559f7b1d50ae38edfd40b0945bf7082d2e.jpg',\n",
       " '2e0e5387077df0a65861674b950b7f65a7ca2705.jpg',\n",
       " 'a571c39e8a0275ea3a3933cb0d608063dffb72e2.jpg',\n",
       " '06b408f64e7a5180bc024a10b5e201592986661d.jpg',\n",
       " '8381010aff0de7a6407dc782ab55d2bffe72e7d3.jpg',\n",
       " '79d908e80aaa2d366168e906e0536bb15f11d10b.jpg',\n",
       " 'ccf1b52ec88fc0fde138cf0a07d44d0e3162435f.jpg',\n",
       " 'd5c69b12e67264957f72a970410e43a587372a0d.jpg',\n",
       " '353835938542c4f206415fb8cf4a76e0662743da.jpg',\n",
       " '4d631f31007acf89afba7f7835b2410b783c0f9c.jpg',\n",
       " '03929a97374ed6a83a48fc8997e201dc559126a3.jpg',\n",
       " '4254b81fc1a984a18eb3f0d93fbc93d45fd9c24d.jpg',\n",
       " 'd2380ed21460a8ab52629468cf7d2c5725c79751.jpg',\n",
       " '256644b78c81b203fea1aeefcd20042b70e8b465.jpg',\n",
       " '5c227d60489c5c46c2c4d0fac5059a82999d5a56.jpg',\n",
       " '6e8cbf612e41a83b6309609dc3385d760155a4a4.jpg',\n",
       " '4f0efa637cd9c498b2d7d0e26aff1a425927fb66.jpg',\n",
       " '04a29674a719d34b10c63e3f299ea483bf9e9ba6.jpg',\n",
       " '66d2f5d4a8c9e81ee476bdc26f322a0ba00985ae.jpg',\n",
       " '6eeee160b75b7c6ece677b5fdf45614c49c6a6de.jpg',\n",
       " 'a8dee63d435a6f49c4a9233cf5aff420c40c6765.jpg',\n",
       " 'af71bc067fd1bacd792817dc87599034f85db112.jpg',\n",
       " 'f0165cc1a4fcf882fb7ad3a85187e7cf8870a63f.jpg',\n",
       " '76c5837b2692691c9fc86c936f16376525b0a981.jpg',\n",
       " '0da2dac9da3f797adfbdeaed999d54935a0a1020.jpg',\n",
       " 'a0d2409f1a28a84f5288b4baa16715bc47c04258.jpg',\n",
       " 'e089c38d86fca8d2dba528956237c3b1a43a711d.jpg',\n",
       " '20712b8d555fc40742e1ee17dca0b157a9e3af9f.jpg',\n",
       " '89c1b16df3f712b06f8d7194c5303ad569046b49.jpg',\n",
       " 'ac7fbe94dcf8e0095ecf6a254465bf08b5ac3a1c.jpg',\n",
       " '3f78cae5b6eb6bc97b96e93d8839a7cfc90f9800.jpg',\n",
       " '71e1de7f22b318145ed936c804d444f4b92f25c7.jpg',\n",
       " 'f381cb6635560f1c617aad38c59869f00d366463.jpg',\n",
       " '84ecdf20e2a3542a859cfc34f5402b5642f3ef1e.jpg',\n",
       " 'be031c290ed85a571cb4501271b3c37b5706bbf4.jpg',\n",
       " 'eb5772ed555dde84fba24f174f250200ee5da709.jpg',\n",
       " '263b9a04c93731036fa2a0cd5b0454f106a31c1a.jpg',\n",
       " '43b41d9ef3dd95cebc9e819f9da059dafa4a06a1.jpg',\n",
       " 'a5bfa3dd75134f635351cde17919ca9d5cb6deb7.jpg',\n",
       " '13877d765fae84cc96300ee6f2e6747812744f32.jpg',\n",
       " 'cec01670a1d5c197b273afa56cd7602225627540.jpg',\n",
       " '533368cb1132188ccb79aba7cce5df2506fa389a.jpg',\n",
       " '7b2fb3cc0a5a71b5b48b29a37759a55acf222c35.jpg',\n",
       " '2e808fe6daf8c596480f34c0c5372d094c01acd5.jpg',\n",
       " 'b0354d62fa2da1d22e527ef0050e071c286ef533.jpg',\n",
       " '8757e9116a2c03e6b6b63205d7100ea28077c8a7.jpg',\n",
       " '38caf8eb4cf710cd9b757c719a5fecc90555df11.jpg',\n",
       " '9b920910d61f7d6fce6b7695a4cafcd70f56a411.jpg',\n",
       " ...}"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "image_paths_tochk = [ i for i in image_paths if i in img_set]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "from PIL import Image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "for path in image_paths_tochk:\n",
    "    img = np.array(Image.open(path).convert('RGB'))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    break\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get the 10 nearest neighbors of a query\n",
    "for query in sumbit_data_loader:\n",
    "    indices, distances = im.get_nearest_neighbors(query, k=10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get nearest neighbors of a query"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get 10 nearest neighbors for a car image\n",
    "for img_type in [classA, classB]:\n",
    "    img = dataset[img_type[0]][0].unsqueeze(0)\n",
    "    print(\"query image\")\n",
    "    imshow(torchvision.utils.make_grid(img))\n",
    "    indices, distances = inference_model.get_nearest_neighbors(img, k=10)\n",
    "    nearest_imgs = [dataset[i][0] for i in indices[0]]\n",
    "    print(\"nearest images\")\n",
    "    imshow(torchvision.utils.make_grid(nearest_imgs))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare two images of the same class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# compare two images of the same class\n",
    "(x, _), (y, _) = dataset[classA[0]], dataset[classA[1]]\n",
    "imshow(torchvision.utils.make_grid(torch.stack([x,y], dim=0)))\n",
    "decision = inference_model.is_match(x.unsqueeze(0), y.unsqueeze(0))\n",
    "print_decision(decision)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare two images of different classes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# compare two images of a different class\n",
    "(x, _), (y, _) = dataset[classA[0]], dataset[classB[0]]\n",
    "imshow(torchvision.utils.make_grid(torch.stack([x,y], dim=0)))\n",
    "decision = inference_model.is_match(x.unsqueeze(0), y.unsqueeze(0))\n",
    "print_decision(decision)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare multiple pairs of images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# compare multiple pairs of images\n",
    "x = torch.zeros(20, 3, 384, 384)\n",
    "y = torch.zeros(20, 3, 384, 384)\n",
    "for i in range(0, 20, 2):\n",
    "    x[i] = dataset[classA[i]][0]\n",
    "    x[i+1] = dataset[classB[i]][0]\n",
    "    y[i] = dataset[classA[i+20]][0]\n",
    "    y[i+1] = dataset[classB[i+20]][0]\n",
    "imshow(torchvision.utils.make_grid(torch.cat((x,y), dim=0), nrow=20), figsize=(30, 3))\n",
    "decision = inference_model.is_match(x, y)\n",
    "for d in decision:\n",
    "    print_decision(d)\n",
    "print(\"accuracy = {}\".format(np.sum(decision)/len(x)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare all pairs within a batch"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# compare all pairs within a batch\n",
    "match_matrix = inference_model.get_matches(x)\n",
    "assert match_matrix[0,0] # the 0th image should match with itself\n",
    "imshow(torchvision.utils.make_grid(torch.stack((x[3],x[4]), dim=0)))\n",
    "print_decision(match_matrix[3,4]) # does the 3rd image match the 4th image?"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# compare all pairs between queries and references\n",
    "match_matrix = inference_model.get_matches(x, y)\n",
    "imshow(torchvision.utils.make_grid(torch.stack((x[6],y[6]), dim=0)))\n",
    "print_decision(match_matrix[6, 6]) # does the 6th query match the 6th reference?"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# make a new model with high threshold\n",
    "match_finder = MatchFinder(distance=CosineSimilarity(), threshold=0.95)\n",
    "inference_model = InferenceModel(model, match_finder=match_finder)\n",
    "\n",
    "# get all matches in tuple form\n",
    "match_tuples = inference_model.get_matches(x, y, return_tuples=True)\n",
    "print(\"MATCHING IMAGE PAIRS\")\n",
    "for i,j in match_tuples:\n",
    "    print(i,j)\n",
    "    imshow(torchvision.utils.make_grid(torch.stack((x[i],y[j]), dim=0)))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}